{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from options import args_parser\n",
    "from update import LocalUpdate, test_inference, ASRLocalUpdate\n",
    "from models import MLP, CNNMnist, CNNFashion_Mnist, CNNCifar, Data2VecAudioForCTC, DataCollatorCTCWithPadding\n",
    "from utils import get_dataset, average_weights, exp_details\n",
    "\n",
    "from transformers import Data2VecAudioConfig, Wav2Vec2Processor\n",
    "from multiprocessing import Pool\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# federated arguments (Notation for the arguments followed from paper)\n",
    "parser.add_argument('--epochs', type=int, default=2,\n",
    "                    help=\"number of rounds of training\")\n",
    "parser.add_argument('--num_users', type=int, default=2,\n",
    "                    help=\"number of users: K\")\n",
    "parser.add_argument('--frac', type=float, default=1.0,\n",
    "                    help='the fraction of clients: C')\n",
    "parser.add_argument('--local_ep', type=int, default=1,\n",
    "                    help=\"the number of local epochs: E\")\n",
    "#parser.add_argument('--local_bs', type=int, default=1,\n",
    "#                    help=\"local batch size: B\")\n",
    "#parser.add_argument('--lr', type=float, default=0.01,\n",
    "#                    help='learning rate')\n",
    "#parser.add_argument('--momentum', type=float, default=0.5,\n",
    "#                    help='SGD momentum (default: 0.5)')\n",
    "\n",
    "# model arguments\n",
    "parser.add_argument('--model', type=str, default='data2vec', help='model name')\n",
    "#parser.add_argument('--kernel_num', type=int, default=9,\n",
    "#                    help='number of each kind of kernel')\n",
    "#parser.add_argument('--kernel_sizes', type=str, default='3,4,5',\n",
    "#                    help='comma-separated kernel size to \\\n",
    "#                    use for convolution')\n",
    "#parser.add_argument('--num_channels', type=int, default=1, help=\"number \\\n",
    "#                    of channels of imgs\")\n",
    "#parser.add_argument('--norm', type=str, default='batch_norm',\n",
    "#                    help=\"batch_norm, layer_norm, or None\")\n",
    "#parser.add_argument('--num_filters', type=int, default=32,\n",
    "#                    help=\"number of filters for conv nets -- 32 for \\\n",
    "#                    mini-imagenet, 64 for omiglot.\")\n",
    "#parser.add_argument('--max_pool', type=str, default='True',\n",
    "#                    help=\"Whether use max pooling rather than \\\n",
    "#                    strided convolutions\")\n",
    "\n",
    "# other arguments\n",
    "parser.add_argument('--dataset', type=str, default='adress', help=\"name \\\n",
    "                    of dataset\") #cifar\n",
    "#parser.add_argument('--num_classes', type=int, default=10, help=\"number \\\n",
    "#                    of classes\")\n",
    "parser.add_argument('--gpu', default=1, help=\"To use cuda, set \\\n",
    "                    to a specific GPU ID. Default set to use CPU.\")\n",
    "#parser.add_argument('--optimizer', type=str, default='sgd', help=\"type \\\n",
    "#                    of optimizer\")\n",
    "#parser.add_argument('--iid', type=int, default=1,\n",
    "#                    help='Default set to IID. Set to 0 for non-IID.')\n",
    "#parser.add_argument('--unequal', type=int, default=0,\n",
    "#                    help='whether to use unequal data splits for  \\\n",
    "#                    non-i.i.d setting (use 0 for equal splits)')\n",
    "#parser.add_argument('--stopping_rounds', type=int, default=10,\n",
    "#                    help='rounds of early stopping')\n",
    "#parser.add_argument('--verbose', type=int, default=1, help='verbose')\n",
    "#parser.add_argument('--seed', type=int, default=1, help='random seed')\n",
    "\n",
    "# additional arguments\n",
    "parser.add_argument('--pretrain_name', type=str, default='facebook/data2vec-audio-large-960h', help=\"str used to load pretrain model\")\n",
    "parser.add_argument('-lam', '--LAMBDA', type=float, default=0.5, help=\"Lambda for GRL\")\n",
    "parser.add_argument('-st', '--STAGE', type=int, default=2, help=\"Current training stage\")\n",
    "parser.add_argument('-GRL', '--GRL', action='store_true', default=False, help=\"True: GRL\")\n",
    "parser.add_argument('-model_in', '--model_in_path', type=str, default=\"/mnt/Internal/FedASR/weitung/HuggingFace/Pretrain/saves/data2vec-audio-large-960h_new1_recall/final/\", help=\"Where the model is saved\")\n",
    "parser.add_argument('-model_out', '--model_out_path', type=str, default=\"./save/data2vec-audio-large-960h_new2_recall_FL\", help=\"Where to save the model\")\n",
    "parser.add_argument('-log', '--log_path', type=str, default=\"data2vec-audio-large-960h_new2_recall_FL.txt\", help=\"name for the txt file\")\n",
    "# 2023/01/08: loss type\n",
    "parser.add_argument('-ad_loss', '--AD_loss', type=str, default=\"recall\", help=\"loss to use for AD classifier\")\n",
    "# 2023/01/18: ckpt\n",
    "parser.add_argument('-ckpt', '--checkpoint', type=str, default=None, help=\"path to checkpoint\")\n",
    "# 2023/02/13: TOGGLE_RATIO\n",
    "parser.add_argument('-toggle_rt', '--TOGGLE_RATIO', type=float, default=0, help=\"To toggle more or less\")\n",
    "# 2023/02/15: GS_TAU, loss weight\n",
    "parser.add_argument('-gs_tau', '--GS_TAU', type=float, default=1, help=\"Tau for gumbel_softmax\")\n",
    "parser.add_argument('-w_loss', '--W_LOSS', type=float, default=None, nargs='+', help=\"weight for HC and AD\")\n",
    "\n",
    "args = parser.parse_args(args=[]) # for jupyter notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train(args, train_dataset, \n",
    "                 test_dataset, idx, epoch, global_weights=None):                    # train function for each client\n",
    "    print(\" process PID\", os.getpid(), \" running\")\n",
    "    \n",
    "    # BUILD MODEL for every process\n",
    "    if args.model == 'data2vec':\n",
    "        mask_time_prob = 0                                                          # change config to avoid training stopping\n",
    "        config = Data2VecAudioConfig.from_pretrained(args.pretrain_name, mask_time_prob=mask_time_prob)\n",
    "        print(\"load from \", args.model_in_path)\n",
    "        model = Data2VecAudioForCTC.from_pretrained(args.model_in_path, config=config, args=args)\n",
    "        print(\"model loaded\")                                                       # load/initialize global model\n",
    "        model.config.ctc_zero_infinity = True                                       # to avoid inf values\n",
    "\n",
    "        global_model = copy.deepcopy(model.arbitrator)                              # only has global toggling network\n",
    "        if global_weights != None:                                                  # if given global_weights\n",
    "            global_model.load_state_dict(global_weights)                            # load it\n",
    "        #else:\n",
    "        #    # copy weights\n",
    "        #    global_weights = copy.deepcopy(global_model.state_dict())                       # save global weight\n",
    "        processor = Wav2Vec2Processor.from_pretrained(args.pretrain_name)\n",
    "        data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "    else:\n",
    "        exit('Error: unrecognized model')\n",
    "\n",
    "    # Set the model to train and send it to device.\n",
    "    device = 'cuda' if args.gpu else 'cpu'\n",
    "    global_model.to(device)\n",
    "    global_model.train()\n",
    "    #print(global_model)\n",
    "\n",
    "    ####################\n",
    "    # 'use client_id generate sub-dataset' to be done\n",
    "    ####################\n",
    "    #print(\"call ASRLocalUpdate\")\n",
    "    local_model = ASRLocalUpdate(args=args, dataset=train_dataset, logger=logger,\n",
    "                        data_collator=data_collator, global_test_dataset=test_dataset, \n",
    "                        processor=processor, client_id=idx)\n",
    "                                                                                    # initial dataset of current client\n",
    "    ####################\n",
    "    # 'use client_id load local model' to be done\n",
    "    # 'save model in final round' to be done\n",
    "    ####################\n",
    "    #print(\"perform update_weight\")\n",
    "    w, loss = local_model.update_weights(\n",
    "        global_arbitrator=copy.deepcopy(global_model), global_round=epoch)          # from global model to train\n",
    "    \n",
    "    #send_end.send([w, loss])                                                        # save model weights and average round loss\n",
    "    #return_dict[str(idx)] = [w, loss]\n",
    "    print(\"PID {} Getting \".format(os.getpid()), \"Done\")\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_get_weight(args, idx, epoch):                               # function to get weight for each client\n",
    "    print(\" process PID\", os.getpid(), \" running\")\n",
    "    # model saved in args.model_out_path + \"_\" + str(idx) + \"/final_\" + str(epoch)\n",
    "    #model_path = args.model_out_path + \"_\" + str(idx) + \"/final_\" + str(epoch)\n",
    "    #model_path = args.model_out_path + \"_client\" + str(idx) + \n",
    "    #\"_round\" + str(global_round) + \"/final\"\n",
    "    model_path = args.model_in_path\n",
    "    # BUILD MODEL for every process\n",
    "    if args.model == 'data2vec':\n",
    "        mask_time_prob = 0                                                          # change config to avoid training stopping\n",
    "        config = Data2VecAudioConfig.from_pretrained(args.pretrain_name, mask_time_prob=mask_time_prob)\n",
    "        model = Data2VecAudioForCTC.from_pretrained(model_path, config=config, args=args)\n",
    "                                                                                    # load local model\n",
    "        print(\"model loaded\")\n",
    "        model.config.ctc_zero_infinity = True                                       # to avoid inf values\n",
    " \n",
    "        arbitrator = copy.deepcopy(model.arbitrator)                                # return weight for toggling network only\n",
    "\n",
    "        return_weights = copy.deepcopy(arbitrator.state_dict())                       # save global weight\n",
    "    else:\n",
    "        exit('Error: unrecognized model')\n",
    "\n",
    "    #return_dict[str(idx)] = return_weights\n",
    "    print(\"PID {} Getting \".format(os.getpid()), \"Done\")\n",
    "    return return_weights, 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimental details:\n",
      "    Model     : data2vec\n",
      "    Global Rounds   : 2\n",
      "\n",
      "    Current Stage   : 2\n",
      "\n",
      "    Loss Type       : recall\n",
      "\n",
      "    Federated parameters:\n",
      "    Number of users    : 2\n",
      "    Fraction of users  : 1.0\n"
     ]
    }
   ],
   "source": [
    "#start_time = time.time()\n",
    "\n",
    "# define paths\n",
    "#path_project = os.path.abspath('..')\n",
    "logger = SummaryWriter('../logs')\n",
    "\n",
    "#args = args_parser()\n",
    "exp_details(args) # print out details based on configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from local...\n",
      "Load data from local...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at dataset/train/cache-eef2ff61fe552b21.arrow\n",
      "Loading cached processed dataset at dataset/train/cache-cd21b7340f9b8047.arrow\n",
      "Loading cached processed dataset at dataset/train/cache-0dd52273b5907da5.arrow\n",
      "Loading cached processed dataset at dataset/train/cache-ba7a9e979f233d88.arrow\n",
      "Loading cached processed dataset at dataset/train/cache-0d40fc390de55f7c.arrow\n",
      "Loading cached processed dataset at dataset/train/cache-f8c6198f1e1fbec6.arrow\n",
      "Loading cached processed dataset at dataset/train/cache-9a77b4114be7ed46.arrow\n",
      "Loading cached processed dataset at dataset/train/cache-2ab0be3c68e13e94.arrow\n",
      "Loading cached processed dataset at dataset/train/cache-2b8608c1545fc612.arrow\n",
      "Loading cached processed dataset at dataset/train/cache-499d91cde6971409.arrow\n",
      "Loading cached processed dataset at dataset/test/cache-04dcfd9c5cab1c0d.arrow\n",
      "Loading cached processed dataset at dataset/test/cache-6a045a1fa580e9fb.arrow\n",
      "Loading cached processed dataset at dataset/test/cache-1353122cf5c10ee8.arrow\n",
      "Loading cached processed dataset at dataset/test/cache-3c799f5fe4590ae2.arrow\n",
      "Loading cached processed dataset at dataset/test/cache-e7dc267ac882f217.arrow\n",
      "Loading cached processed dataset at dataset/test/cache-7e131f6db55f1d2b.arrow\n",
      "Loading cached processed dataset at dataset/test/cache-31375e65f1ea679d.arrow\n",
      "Loading cached processed dataset at dataset/test/cache-150347809b60963c.arrow\n",
      "Loading cached processed dataset at dataset/test/cache-12265edae30dd1f8.arrow\n",
      "Loading cached processed dataset at dataset/test/cache-109ed1d9bc89710e.arrow\n"
     ]
    }
   ],
   "source": [
    "#if args.gpu_id:\n",
    "#    torch.cuda.set_device(args.gpu_id)\n",
    "#device = 'cuda' if args.gpu else 'cpu'\n",
    "\n",
    "# load dataset and user groups\n",
    "train_dataset, test_dataset, user_groups = get_dataset(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID相關code先跳過"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:10<00:00, 20.58ex/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'array', 'text', 'dementia_labels', 'input_values', 'labels', 'user_IDs'],\n",
       "    num_rows: 206\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_IDs = train_dataset.map(lambda x: {\"user_IDs\": x[\"path\"].split(\"_\")[0]})\n",
    "user_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S082', 'S070', 'S081', 'S073', 'S024', 'S062', 'S100', 'S132', 'S111', 'S001', 'S012', 'S009', 'S028', 'S079', 'S108', 'S151', 'S094', 'S048', 'S003', 'S055', 'S077', 'S043', 'S002', 'S138', 'S126', 'S029', 'S107', 'S092', 'S089', 'S011', 'S148', 'S135', 'S139', 'S129', 'S015', 'S116', 'S090', 'S101', 'S128', 'S005', 'S004', 'S041', 'S149', 'S040', 'S150', 'S039', 'S156', 'S061', 'S141', 'S137', 'S080', 'S056', 'S038', 'S076', 'S064', 'S007', 'S063', 'S140', 'S019', 'S130', 'S114', 'S124', 'S033', 'S118', 'S021', 'S051', 'S084', 'S032', 'S153', 'S142', 'S016', 'S103', 'S145', 'S013', 'S095', 'S034', 'S006', 'S083', 'S027', 'S025', 'S017', 'S097', 'S086', 'S052', 'S068', 'S096']\n"
     ]
    }
   ],
   "source": [
    "mylist = user_IDs[\"user_IDs\"]\n",
    "mylist = list(dict.fromkeys(mylist))\n",
    "print(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.16s/ba]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['S094_PAR_12_75580_76503.wav',\n",
       " 'S055_PAR_15_41550_42647.wav',\n",
       " 'S094_PAR_8_48996_55998.wav',\n",
       " 'S055_PAR_9_21400_22280.wav',\n",
       " 'S055_PAR_14_39953_41550.wav',\n",
       " 'S094_PAR_4_25903_28918.wav',\n",
       " 'S055_PAR_4_12000_14377.wav',\n",
       " 'S094_INV_3_74801_75580.wav']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate sub- training set for given user-ID\n",
    "start_with_ar = train_dataset.filter(lambda example: (example[\"path\"].startswith(\"S055\")) or (example[\"path\"].startswith(\"S094\")))\n",
    "start_with_ar[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar_iid(dataset, num_users):\n",
    "    \"\"\"\n",
    "    Sample I.I.D. client data from CIFAR10 dataset\n",
    "    :param dataset:\n",
    "    :param num_users:\n",
    "    :return: dict of image index\n",
    "    \"\"\"\n",
    "    num_items = int(len(dataset)/num_users)\n",
    "    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n",
    "    for i in range(num_users):\n",
    "        dict_users[i] = set(np.random.choice(all_idxs, num_items,\n",
    "                                             replace=False))\n",
    "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
    "    return dict_users\n",
    "def cifar_noniid(dataset, num_users):\n",
    "    \"\"\"\n",
    "    Sample non-I.I.D client data from CIFAR10 dataset\n",
    "    :param dataset:\n",
    "    :param num_users:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    num_shards, num_imgs = 200, 250\n",
    "    idx_shard = [i for i in range(num_shards)]\n",
    "    dict_users = {i: np.array([]) for i in range(num_users)}\n",
    "    idxs = np.arange(num_shards*num_imgs)\n",
    "    # labels = dataset.train_labels.numpy()\n",
    "    labels = np.array(dataset.train_labels)\n",
    "\n",
    "    # sort labels\n",
    "    idxs_labels = np.vstack((idxs, labels))\n",
    "    idxs_labels = idxs_labels[:, idxs_labels[1, :].argsort()]\n",
    "    idxs = idxs_labels[0, :]\n",
    "\n",
    "    # divide and assign\n",
    "    for i in range(num_users):\n",
    "        rand_set = set(np.random.choice(idx_shard, 2, replace=False))\n",
    "        idx_shard = list(set(idx_shard) - rand_set)\n",
    "        for rand in rand_set:\n",
    "            dict_users[i] = np.concatenate(\n",
    "                (dict_users[i], idxs[rand*num_imgs:(rand+1)*num_imgs]), axis=0)\n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面開始繼續跑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [參考](https://stackoverflow.com/questions/10415028/how-to-get-the-return-value-of-a-function-passed-to-multiprocessing-process): 不同multi-process寫法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " process PID  process PID 29867342986733   running\n",
      " running\n",
      "lambda =  tensor(0.5000)\n",
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n",
      "Current stage: 2\n",
      "model loaded\n",
      "PID 2986733 Getting  Done\n",
      "model loaded\n",
      "PID 2986734 Getting  Done\n"
     ]
    }
   ],
   "source": [
    "# multi-process ver1\n",
    "from multiprocessing import Pool\n",
    "\"\"\"\n",
    "def Get_phonationdictbag_map(parameters):\n",
    "    args, train_dataset, logger, test_dataset, idx, epoch, global_weights = parameters\n",
    "    print(\" process PID\", os.getpid(), \" running\")\n",
    "    for file in files:\n",
    "        ///\n",
    "        your code\n",
    "        ///\n",
    "    print(\"PID {} Getting \".format(os.getpid()), \"Done\")\n",
    "client_train(args, train_dataset, logger, \n",
    "                 test_dataset, idx, epoch, global_weights=None)\n",
    "\"\"\"\n",
    "#interval=20\n",
    "#parameters_lst = []\n",
    "#for i in range(args.num_users):                       # for each client\n",
    "    \n",
    "#    keys.append(files[i:i+interval])\n",
    "#flat_keys=[item for sublist in keys for item in sublist]\n",
    "#assert len(flat_keys) == len(files)\n",
    "\n",
    "#final_result = pool.starmap(Get_phonationdictbag_map, [([file_block])    for file_block in tqdm(keys)])\n",
    "#client_get_weight(args, idx, epoch)\n",
    "pool = Pool(int(os.cpu_count()))\n",
    "epoch = 0\n",
    "final_result = pool.starmap(client_get_weight, [(args, idx, epoch) for idx in range(args.num_users)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('weight',\n",
       "               tensor([[-0.0123,  0.0295,  0.0211,  ..., -0.0300,  0.0236,  0.0029],\n",
       "                       [ 0.0174,  0.0111,  0.0379,  ...,  0.0432, -0.0009,  0.0588],\n",
       "                       [-0.0086, -0.0458, -0.0061,  ...,  0.0018, -0.0037, -0.0036],\n",
       "                       ...,\n",
       "                       [ 0.0082, -0.0028, -0.0058,  ...,  0.0179, -0.0070, -0.0085],\n",
       "                       [-0.0223, -0.0279,  0.0233,  ...,  0.0101,  0.0206,  0.0180],\n",
       "                       [-0.0271,  0.0189,  0.0437,  ...,  0.0140, -0.0013,  0.0029]])),\n",
       "              ('bias', tensor([0., 0., 0.,  ..., 0., 0., 0.]))]),\n",
       " 0.05)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 只跑一個round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 1 |\n",
      "\n",
      " process PID process PID 4098957  4098960 running \n",
      " running\n",
      "load from  /mnt/Internal/FedASR/weitung/HuggingFace/Pretrain/saves/data2vec-audio-large-960h_new1_recall/final/load from \n",
      " /mnt/Internal/FedASR/weitung/HuggingFace/Pretrain/saves/data2vec-audio-large-960h_new1_recall/final/\n",
      "lambda =  tensor(0.5000)\n",
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n",
      "Current stage: 2\n",
      "model loaded\n",
      "model loaded\n",
      "initialize ASRLocalUpdate\n",
      "Generating client training set for client  1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at dataset/train/cache-fb08d3bc1bef9380.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n",
      "initialize ASRLocalUpdate\n",
      "Generating client training set for client  0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at dataset/train/cache-e6128932aeaa194b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n",
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n",
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  ready to train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: text, path, array. If text, path, array are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  ready to train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: text, path, array. If text, path, array are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 419\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 419\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='419' max='419' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [419/419 04:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 543\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='543' max='543' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [543/543 06:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>538.837900</td>\n",
       "      <td>1651.486816</td>\n",
       "      <td>0.255931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: text, path, array. If text, path, array are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round0/final\n",
      "Configuration saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round0/final/config.json\n",
      "Model weights saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round0/final/pytorch_model.bin\n",
      "Feature extractor saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round0/final/preprocessor_config.json\n",
      "loading configuration file https://huggingface.co/facebook/data2vec-audio-large-960h/resolve/main/config.json from cache at /home/weitung/.cache/huggingface/transformers/a5e291023d6dd7ec0034390cee6d97f07e340fb24c68c7b5f3ec8d017a6fd29d.ed9b9e83fb80348aa91a073138fc7a0f44e669fc412c9c4bc98857f45bfd4330\n",
      "Model config Data2VecAudioConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Data2VecAudioForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 768,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_pos_kernel_size\": 19,\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0,\n",
      "  \"model_type\": \"data2vec-audio\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 5,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 768,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading weights file ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round0/final/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing Data2VecAudioForCTC.\n",
      "\n",
      "All the weights of Data2VecAudioForCTC were initialized from the model checkpoint at ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round0/final.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Data2VecAudioForCTC for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID 4098960 Getting  Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./save/data2vec-audio-large-960h_new2_recall_FL_0/checkpoint-500\n",
      "Configuration saved in ./save/data2vec-audio-large-960h_new2_recall_FL_0/checkpoint-500/config.json\n",
      "Model weights saved in ./save/data2vec-audio-large-960h_new2_recall_FL_0/checkpoint-500/pytorch_model.bin\n",
      "Feature extractor saved in ./save/data2vec-audio-large-960h_new2_recall_FL_0/checkpoint-500/preprocessor_config.json\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round0/final\n",
      "Configuration saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round0/final/config.json\n",
      "Model weights saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round0/final/pytorch_model.bin\n",
      "Feature extractor saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round0/final/preprocessor_config.json\n",
      "loading configuration file https://huggingface.co/facebook/data2vec-audio-large-960h/resolve/main/config.json from cache at /home/weitung/.cache/huggingface/transformers/a5e291023d6dd7ec0034390cee6d97f07e340fb24c68c7b5f3ec8d017a6fd29d.ed9b9e83fb80348aa91a073138fc7a0f44e669fc412c9c4bc98857f45bfd4330\n",
      "Model config Data2VecAudioConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Data2VecAudioForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 768,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_pos_kernel_size\": 19,\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0,\n",
      "  \"model_type\": \"data2vec-audio\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 5,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 768,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading weights file ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round0/final/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing Data2VecAudioForCTC.\n",
      "\n",
      "All the weights of Data2VecAudioForCTC were initialized from the model checkpoint at ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round0/final.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Data2VecAudioForCTC for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID 4098957 Getting  Done\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "train_loss, test_wer = [], []\n",
    "val_acc_list, net_list = [], []\n",
    "cv_loss, cv_acc = [], []\n",
    "print_every = 2\n",
    "val_loss_pre, counter = 0, 0\n",
    "global_weights = None                                                           # initial global_weights\n",
    "epoch = 0\n",
    "#for epoch in tqdm(range(args.epochs)):                                          # train for given global rounds\n",
    "#local_weights, local_losses = [], []                                        # weights and losses of training clients of this round\n",
    "print(f'\\n | Global Training Round : {epoch+1} |\\n')                        # print current round\n",
    "\n",
    "m = max(int(args.frac * args.num_users), 1)                                 # num of clients to train, min:1\n",
    "idxs_users = np.random.choice(range(args.num_users), m, replace=False)      # select by client_id\n",
    "\n",
    "pool = Pool(int(os.cpu_count()))\n",
    "final_result = pool.starmap(client_train, [(args, train_dataset, \n",
    "                 test_dataset, idx, epoch, global_weights) for idx in idxs_users])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(OrderedDict([('weight',\n",
       "                tensor([[ 0.0102,  0.0241,  0.0207,  ..., -0.0309,  0.0183,  0.0087],\n",
       "                        [ 0.0156,  0.0400,  0.0283,  ...,  0.0336, -0.0089,  0.0473],\n",
       "                        [-0.0214, -0.0527, -0.0180,  ...,  0.0068, -0.0065, -0.0028],\n",
       "                        ...,\n",
       "                        [-0.0171,  0.0124, -0.0117,  ...,  0.1232,  0.0053,  0.0296],\n",
       "                        [-0.0945, -0.0258,  0.0358,  ...,  0.0473,  0.1927,  0.0342],\n",
       "                        [ 0.0357, -0.0304,  0.0311,  ...,  0.0296, -0.0344,  0.1237]])),\n",
       "               ('bias',\n",
       "                tensor([ 0.0103, -0.0126,  0.0101,  ...,  0.0506,  0.0309,  0.0172]))]),\n",
       "  580.0991165976059),\n",
       " (OrderedDict([('weight',\n",
       "                tensor([[ 0.0037,  0.0308,  0.0278,  ..., -0.0259,  0.0077,  0.0016],\n",
       "                        [ 0.0200,  0.0299,  0.0313,  ...,  0.0398, -0.0063,  0.0532],\n",
       "                        [-0.0211, -0.0469, -0.0152,  ...,  0.0076, -0.0046, -0.0008],\n",
       "                        ...,\n",
       "                        [-0.0258,  0.0156, -0.0210,  ...,  0.0783, -0.0094,  0.0062],\n",
       "                        [-0.0482, -0.0226,  0.0451,  ...,  0.0186,  0.1086,  0.0023],\n",
       "                        [-0.0021, -0.0034,  0.0231,  ...,  0.0396, -0.0215,  0.0647]])),\n",
       "               ('bias',\n",
       "                tensor([ 0.0027, -0.0052,  0.0094,  ...,  0.0360,  0.0097,  0.0240]))]),\n",
       "  639.9700178997614)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_weights = []\n",
    "local_losses = []\n",
    "for idx in range(len(final_result)):\n",
    "    w, loss = final_result[idx]\n",
    "    local_weights.append(w)\n",
    "    local_losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 0.0069,  0.0274,  0.0242,  ..., -0.0284,  0.0130,  0.0051],\n",
       "                      [ 0.0178,  0.0350,  0.0298,  ...,  0.0367, -0.0076,  0.0502],\n",
       "                      [-0.0213, -0.0498, -0.0166,  ...,  0.0072, -0.0055, -0.0018],\n",
       "                      ...,\n",
       "                      [-0.0214,  0.0140, -0.0163,  ...,  0.1007, -0.0020,  0.0179],\n",
       "                      [-0.0713, -0.0242,  0.0404,  ...,  0.0330,  0.1507,  0.0183],\n",
       "                      [ 0.0168, -0.0169,  0.0271,  ...,  0.0346, -0.0279,  0.0942]])),\n",
       "             ('bias',\n",
       "              tensor([ 0.0065, -0.0089,  0.0098,  ...,  0.0433,  0.0203,  0.0206]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_weights = average_weights(local_weights)\n",
    "global_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 2 |\n",
      "\n",
      " process PID process PID  41147454114746   running running\n",
      "\n",
      "load from  /mnt/Internal/FedASR/weitung/HuggingFace/Pretrain/saves/data2vec-audio-large-960h_new1_recall/final/\n",
      "load from  /mnt/Internal/FedASR/weitung/HuggingFace/Pretrain/saves/data2vec-audio-large-960h_new1_recall/final/\n",
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n",
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-218:\n",
      "Process ForkPoolWorker-242:\n",
      "Process ForkPoolWorker-258:\n",
      "Process ForkPoolWorker-231:\n",
      "Process ForkPoolWorker-137:\n",
      "Process ForkPoolWorker-171:\n",
      "Process ForkPoolWorker-182:\n",
      "Process ForkPoolWorker-203:\n",
      "Process ForkPoolWorker-189:\n",
      "Process ForkPoolWorker-158:\n",
      "Process ForkPoolWorker-211:\n",
      "Process ForkPoolWorker-255:\n",
      "Process ForkPoolWorker-167:\n",
      "Process ForkPoolWorker-180:\n",
      "Process ForkPoolWorker-165:\n",
      "Process ForkPoolWorker-247:\n",
      "Process ForkPoolWorker-253:\n",
      "Process ForkPoolWorker-235:\n",
      "Process ForkPoolWorker-205:\n",
      "Process ForkPoolWorker-250:\n",
      "Process ForkPoolWorker-199:\n",
      "Process ForkPoolWorker-184:\n",
      "Process ForkPoolWorker-142:\n",
      "Process ForkPoolWorker-221:\n",
      "Process ForkPoolWorker-179:\n",
      "Process ForkPoolWorker-174:\n",
      "Process ForkPoolWorker-196:\n",
      "Process ForkPoolWorker-168:\n",
      "Process ForkPoolWorker-197:\n",
      "Process ForkPoolWorker-236:\n",
      "Process ForkPoolWorker-140:\n",
      "Process ForkPoolWorker-181:\n",
      "Process ForkPoolWorker-188:\n",
      "Process ForkPoolWorker-183:\n",
      "Process ForkPoolWorker-254:\n",
      "Process ForkPoolWorker-207:\n",
      "Process ForkPoolWorker-240:\n",
      "Process ForkPoolWorker-175:\n",
      "Process ForkPoolWorker-191:\n",
      "Process ForkPoolWorker-225:\n",
      "Process ForkPoolWorker-238:\n",
      "Process ForkPoolWorker-257:\n",
      "Process ForkPoolWorker-178:\n",
      "Process ForkPoolWorker-186:\n",
      "Process ForkPoolWorker-213:\n",
      "Process ForkPoolWorker-206:\n",
      "Process ForkPoolWorker-187:\n",
      "Process ForkPoolWorker-249:\n",
      "Process ForkPoolWorker-256:\n",
      "Process ForkPoolWorker-152:\n",
      "Process ForkPoolWorker-200:\n",
      "Process ForkPoolWorker-154:\n",
      "Process ForkPoolWorker-195:\n",
      "Process ForkPoolWorker-252:\n",
      "Process ForkPoolWorker-239:\n",
      "Process ForkPoolWorker-149:\n",
      "Process ForkPoolWorker-172:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m idxs_users \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mnum_users), m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)      \u001b[38;5;66;03m# select by client_id\u001b[39;00m\n\u001b[1;32m     12\u001b[0m pool \u001b[38;5;241m=\u001b[39m Pool(\u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39mcpu_count()))\n\u001b[0;32m---> 13\u001b[0m final_result \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midxs_users\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py:372\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/flwr-huggingface/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/.conda/envs/flwr-huggingface/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-131:\n",
      "Process ForkPoolWorker-166:\n",
      "Process ForkPoolWorker-170:\n",
      "Process ForkPoolWorker-145:\n",
      "Process ForkPoolWorker-237:\n",
      "Process ForkPoolWorker-141:\n",
      "Process ForkPoolWorker-223:\n",
      "Process ForkPoolWorker-150:\n",
      "Process ForkPoolWorker-243:\n",
      "Process ForkPoolWorker-138:\n",
      "Process ForkPoolWorker-163:\n",
      "Process ForkPoolWorker-202:\n",
      "Process ForkPoolWorker-192:\n",
      "Process ForkPoolWorker-177:\n",
      "Process ForkPoolWorker-146:\n",
      "Process ForkPoolWorker-227:\n",
      "Process ForkPoolWorker-173:\n",
      "Process ForkPoolWorker-210:\n",
      "Process ForkPoolWorker-134:\n",
      "Process ForkPoolWorker-194:\n",
      "Process ForkPoolWorker-241:\n",
      "Process ForkPoolWorker-248:\n",
      "Process ForkPoolWorker-234:\n",
      "Process ForkPoolWorker-198:\n",
      "Process ForkPoolWorker-228:\n",
      "Process ForkPoolWorker-208:\n",
      "Process ForkPoolWorker-161:\n",
      "Process ForkPoolWorker-217:\n",
      "Process ForkPoolWorker-144:\n",
      "Process ForkPoolWorker-246:\n",
      "Process ForkPoolWorker-164:\n",
      "Process ForkPoolWorker-245:\n",
      "Process ForkPoolWorker-136:\n",
      "Process ForkPoolWorker-229:\n",
      "Process ForkPoolWorker-143:\n",
      "Process ForkPoolWorker-244:\n",
      "Process ForkPoolWorker-135:\n",
      "Process ForkPoolWorker-193:\n",
      "Process ForkPoolWorker-204:\n",
      "Process ForkPoolWorker-147:\n",
      "Process ForkPoolWorker-219:\n",
      "Process ForkPoolWorker-232:\n",
      "Process ForkPoolWorker-156:\n",
      "Process ForkPoolWorker-162:\n",
      "Process ForkPoolWorker-169:\n",
      "Process ForkPoolWorker-151:\n",
      "Process ForkPoolWorker-185:\n",
      "Process ForkPoolWorker-155:\n",
      "Process ForkPoolWorker-201:\n",
      "Process ForkPoolWorker-133:\n",
      "Process ForkPoolWorker-233:\n",
      "Process ForkPoolWorker-157:\n",
      "Process ForkPoolWorker-160:\n",
      "Process ForkPoolWorker-224:\n",
      "Process ForkPoolWorker-132:\n",
      "Process ForkPoolWorker-226:\n",
      "Process ForkPoolWorker-148:\n",
      "Process ForkPoolWorker-214:\n",
      "Process ForkPoolWorker-190:\n",
      "Process ForkPoolWorker-209:\n",
      "Process ForkPoolWorker-220:\n",
      "Process ForkPoolWorker-139:\n",
      "Process ForkPoolWorker-176:\n",
      "Process ForkPoolWorker-159:\n",
      "Process ForkPoolWorker-153:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-215:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-216:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-212:\n",
      "Process ForkPoolWorker-222:\n",
      "Process ForkPoolWorker-251:\n",
      "Process ForkPoolWorker-230:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "pool.close()\n",
    "pool.terminate()\n",
    "\n",
    "epoch = 1\n",
    "#for epoch in tqdm(range(args.epochs)):                                          # train for given global rounds\n",
    "#local_weights, local_losses = [], []                                        # weights and losses of training clients of this round\n",
    "print(f'\\n | Global Training Round : {epoch+1} |\\n')                        # print current round\n",
    "\n",
    "m = max(int(args.frac * args.num_users), 1)                                 # num of clients to train, min:1\n",
    "idxs_users = np.random.choice(range(args.num_users), m, replace=False)      # select by client_id\n",
    "\n",
    "pool = Pool(int(os.cpu_count()))\n",
    "final_result = pool.starmap(client_train, [(args, train_dataset, \n",
    "                 test_dataset, idx, epoch, global_weights) for idx in idxs_users])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 跑多個round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                | 0/2 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Queue objects should only be shared between processes through inheritance",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m idxs_users \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mnum_users), m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)      \u001b[38;5;66;03m# select by client_id\u001b[39;00m\n\u001b[1;32m     14\u001b[0m pool \u001b[38;5;241m=\u001b[39m Pool(\u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39mcpu_count()))\n\u001b[0;32m---> 15\u001b[0m final_result \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midxs_users\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m local_weights \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m local_losses \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py:372\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/pool.py:537\u001b[0m, in \u001b[0;36mPool._handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     \u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     job, idx \u001b[38;5;241m=\u001b[39m task[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/connection.py:206\u001b[0m, in \u001b[0;36m_ConnectionBase.send\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_writable()\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_bytes(\u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/reduction.py:51\u001b[0m, in \u001b[0;36mForkingPickler.dumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdumps\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     50\u001b[0m     buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetbuffer()\n",
      "File \u001b[0;32m~/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/queues.py:58\u001b[0m, in \u001b[0;36mQueue.__getstate__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getstate__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 58\u001b[0m     \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_spawning\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_epipe, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maxsize, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer,\n\u001b[1;32m     60\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wlock, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opid)\n",
      "File \u001b[0;32m~/.conda/envs/flwr-huggingface/lib/python3.8/multiprocessing/context.py:359\u001b[0m, in \u001b[0;36massert_spawning\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_spawning\u001b[39m(obj):\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m get_spawning_popen() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    360\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m objects should only be shared between processes\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    361\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m through inheritance\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    362\u001b[0m             )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Queue objects should only be shared between processes through inheritance"
     ]
    }
   ],
   "source": [
    "train_loss, test_wer = [], []\n",
    "val_acc_list, net_list = [], []\n",
    "cv_loss, cv_acc = [], []\n",
    "print_every = 2\n",
    "val_loss_pre, counter = 0, 0\n",
    "global_weights = None                                                           # initial global_weights\n",
    "for epoch in tqdm(range(args.epochs)):                                          # train for given global rounds\n",
    "    #local_weights, local_losses = [], []                                        # weights and losses of training clients of this round\n",
    "    print(f'\\n | Global Training Round : {epoch+1} |\\n')                        # print current round\n",
    "\n",
    "    m = max(int(args.frac * args.num_users), 1)                                 # num of clients to train, min:1\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)      # select by client_id\n",
    "\n",
    "    pool = Pool(int(os.cpu_count()))\n",
    "    final_result = pool.starmap(client_train, [(args, train_dataset, logger, test_dataset, idx, epoch, global_weights) for idx in idxs_users])\n",
    "    \n",
    "    local_weights = []\n",
    "    local_losses = []\n",
    "    for idx in len(final_result):\n",
    "        w, loss = final_result[idx]\n",
    "        local_weights.append(w)\n",
    "        local_losses.append(loss)\n",
    "\n",
    "    print(\"local weights: \", local_weights)\n",
    "    # get global weights by averaging local weights\n",
    "    global_weights = average_weights(local_weights)\n",
    "    print(\"global wegiths: \", global_weights)\n",
    "\n",
    "    # update global weights\n",
    "    #global_model.load_state_dict(global_weights)\n",
    "\n",
    "    loss_avg = sum(local_losses) / len(local_losses)                # average losses from participated client\n",
    "    train_loss.append(loss_avg)                                     # save loss for this round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以下其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 1 |\n",
      "\n",
      "start of client # 1\n",
      "start of client # 0\n",
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n",
      "model loaded\n",
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n",
      "model loaded\n",
      "initialize ASRLocalUpdate\n",
      "Generating client training set for client  0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at dataset/train/cache-e6128932aeaa194b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n",
      "initialize ASRLocalUpdate\n",
      "Generating client training set for client  1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at dataset/train/cache-fb08d3bc1bef9380.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n",
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n",
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  ready to train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: array, text, path. If array, text, path are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  ready to train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: array, text, path. If array, text, path are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 419\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 419\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 543\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='419' max='419' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [419/419 04:17, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='543' max='543' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [543/543 11:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>538.837900</td>\n",
       "      <td>1651.486816</td>\n",
       "      <td>0.255931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round0/final\n",
      "Configuration saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round0/final/config.json\n",
      "Model weights saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round0/final/pytorch_model.bin\n",
      "Feature extractor saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round0/final/preprocessor_config.json\n",
      "loading configuration file https://huggingface.co/facebook/data2vec-audio-large-960h/resolve/main/config.json from cache at /home/weitung/.cache/huggingface/transformers/a5e291023d6dd7ec0034390cee6d97f07e340fb24c68c7b5f3ec8d017a6fd29d.ed9b9e83fb80348aa91a073138fc7a0f44e669fc412c9c4bc98857f45bfd4330\n",
      "Model config Data2VecAudioConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Data2VecAudioForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 768,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_pos_kernel_size\": 19,\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0,\n",
      "  \"model_type\": \"data2vec-audio\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 5,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 768,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading weights file ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round0/final/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing Data2VecAudioForCTC.\n",
      "\n",
      "All the weights of Data2VecAudioForCTC were initialized from the model checkpoint at ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round0/final.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Data2VecAudioForCTC for predictions without further training.\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: array, text, path. If array, text, path are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./save/data2vec-audio-large-960h_new2_recall_FL_0/checkpoint-500\n",
      "Configuration saved in ./save/data2vec-audio-large-960h_new2_recall_FL_0/checkpoint-500/config.json\n",
      "Model weights saved in ./save/data2vec-audio-large-960h_new2_recall_FL_0/checkpoint-500/pytorch_model.bin\n",
      "Feature extractor saved in ./save/data2vec-audio-large-960h_new2_recall_FL_0/checkpoint-500/preprocessor_config.json\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round0/final\n",
      "Configuration saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round0/final/config.json\n",
      "Model weights saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round0/final/pytorch_model.bin\n",
      "Feature extractor saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round0/final/preprocessor_config.json\n",
      "loading configuration file https://huggingface.co/facebook/data2vec-audio-large-960h/resolve/main/config.json from cache at /home/weitung/.cache/huggingface/transformers/a5e291023d6dd7ec0034390cee6d97f07e340fb24c68c7b5f3ec8d017a6fd29d.ed9b9e83fb80348aa91a073138fc7a0f44e669fc412c9c4bc98857f45bfd4330\n",
      "Model config Data2VecAudioConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Data2VecAudioForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 768,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_pos_kernel_size\": 19,\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0,\n",
      "  \"model_type\": \"data2vec-audio\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 5,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 768,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading weights file ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round0/final/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing Data2VecAudioForCTC.\n",
      "\n",
      "All the weights of Data2VecAudioForCTC were initialized from the model checkpoint at ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round0/final.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Data2VecAudioForCTC for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 2 |\n",
      "\n",
      "start of client # 1\n",
      "start of client # 0\n",
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n",
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n",
      "model loaded\n",
      "model loaded\n",
      "initialize ASRLocalUpdate\n",
      "Generating client training set for client  0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at dataset/train/cache-e6128932aeaa194b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n",
      "initialize ASRLocalUpdate\n",
      "Generating client training set for client  1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at dataset/train/cache-fb08d3bc1bef9380.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n",
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n",
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ready to train! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: array, text, path. If array, text, path are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  ready to train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: array, text, path. If array, text, path are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 419\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 419\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 543\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='543' max='543' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [543/543 12:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>538.837900</td>\n",
       "      <td>1651.486816</td>\n",
       "      <td>0.255931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='419' max='419' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [419/419 05:17, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round1/final\n",
      "Configuration saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round1/final/config.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: array, text, path. If array, text, path are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 1\n",
      "Model weights saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round1/final/pytorch_model.bin\n",
      "Feature extractor saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round1/final/preprocessor_config.json\n",
      "loading configuration file https://huggingface.co/facebook/data2vec-audio-large-960h/resolve/main/config.json from cache at /home/weitung/.cache/huggingface/transformers/a5e291023d6dd7ec0034390cee6d97f07e340fb24c68c7b5f3ec8d017a6fd29d.ed9b9e83fb80348aa91a073138fc7a0f44e669fc412c9c4bc98857f45bfd4330\n",
      "Model config Data2VecAudioConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Data2VecAudioForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 768,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_pos_kernel_size\": 19,\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0,\n",
      "  \"model_type\": \"data2vec-audio\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 5,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 768,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading weights file ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round1/final/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing Data2VecAudioForCTC.\n",
      "\n",
      "All the weights of Data2VecAudioForCTC were initialized from the model checkpoint at ./save/data2vec-audio-large-960h_new2_recall_FL_client1_round1/final.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Data2VecAudioForCTC for predictions without further training.\n",
      "Saving model checkpoint to ./save/data2vec-audio-large-960h_new2_recall_FL_0/checkpoint-500\n",
      "Configuration saved in ./save/data2vec-audio-large-960h_new2_recall_FL_0/checkpoint-500/config.json\n",
      "Model weights saved in ./save/data2vec-audio-large-960h_new2_recall_FL_0/checkpoint-500/pytorch_model.bin\n",
      "Feature extractor saved in ./save/data2vec-audio-large-960h_new2_recall_FL_0/checkpoint-500/preprocessor_config.json\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round1/final\n",
      "Configuration saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round1/final/config.json\n",
      "Model weights saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round1/final/pytorch_model.bin\n",
      "Feature extractor saved in ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round1/final/preprocessor_config.json\n",
      "loading configuration file https://huggingface.co/facebook/data2vec-audio-large-960h/resolve/main/config.json from cache at /home/weitung/.cache/huggingface/transformers/a5e291023d6dd7ec0034390cee6d97f07e340fb24c68c7b5f3ec8d017a6fd29d.ed9b9e83fb80348aa91a073138fc7a0f44e669fc412c9c4bc98857f45bfd4330\n",
      "Model config Data2VecAudioConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Data2VecAudioForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 768,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_pos_kernel_size\": 19,\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0,\n",
      "  \"model_type\": \"data2vec-audio\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 5,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 768,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading weights file ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round1/final/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing Data2VecAudioForCTC.\n",
      "\n",
      "All the weights of Data2VecAudioForCTC were initialized from the model checkpoint at ./save/data2vec-audio-large-960h_new2_recall_FL_client0_round1/final.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Data2VecAudioForCTC for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "train_loss, test_wer = [], []\n",
    "val_acc_list, net_list = [], []\n",
    "cv_loss, cv_acc = [], []\n",
    "print_every = 2\n",
    "val_loss_pre, counter = 0, 0\n",
    "global_weights = None    \n",
    "for epoch in range(2):\n",
    "    #for epoch in tqdm(range(args.epochs)):                                          # train for given global rounds\n",
    "    #local_weights, local_losses = [], []                                        # weights and losses of training clients of this round\n",
    "    print(f'\\n | Global Training Round : {epoch+1} |\\n')                        # print current round\n",
    "\n",
    "    m = max(int(args.frac * args.num_users), 1)                                 # num of clients to train, min:1\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)      # select by client_id\n",
    "\n",
    "    manager = multiprocessing.Manager()\n",
    "    return_dict = manager.dict()\n",
    "    jobs = []\n",
    "    #pipe_list = []\n",
    "    for idx in idxs_users:                                                      # for each training client\n",
    "\n",
    "        print(\"start of client #\", idx)\n",
    "        #recv_end, send_end = multiprocessing.Pipe(False)\n",
    "        p = multiprocessing.Process(target=client_train, args=(return_dict,\n",
    "                args, train_dataset, logger, test_dataset, idx, epoch, global_weights))\n",
    "\n",
    "        #p = multiprocessing.Process(target=client_get_weight, args=(return_dict, args, idx, epoch))\n",
    "        jobs.append(p)\n",
    "        #pipe_list.append(recv_end)\n",
    "        p.start()\n",
    "\n",
    "        #local_weights.append(copy.deepcopy(w))                      # save weight for this client\n",
    "        #local_losses.append(copy.deepcopy(loss))                    # save loss for this client\n",
    "    for proc in jobs:\n",
    "        proc.join()\n",
    "        #proc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '0']\n"
     ]
    }
   ],
   "source": [
    "print(return_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "for idx in idxs_users:                                                      # for each training client\n",
    "    # get model weights from saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_weights = []\n",
    "local_losses = []\n",
    "for key in return_dict.keys():\n",
    "    w, loss = return_dict[key]\n",
    "    local_weights.append(w)\n",
    "    local_losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 0.0069,  0.0274,  0.0242,  ..., -0.0284,  0.0130,  0.0051],\n",
       "                      [ 0.0178,  0.0350,  0.0298,  ...,  0.0367, -0.0076,  0.0502],\n",
       "                      [-0.0213, -0.0498, -0.0166,  ...,  0.0072, -0.0055, -0.0018],\n",
       "                      ...,\n",
       "                      [-0.0214,  0.0140, -0.0163,  ...,  0.1007, -0.0020,  0.0179],\n",
       "                      [-0.0713, -0.0242,  0.0404,  ...,  0.0330,  0.1507,  0.0183],\n",
       "                      [ 0.0168, -0.0169,  0.0271,  ...,  0.0346, -0.0279,  0.0942]])),\n",
       "             ('bias',\n",
       "              tensor([ 0.0065, -0.0089,  0.0098,  ...,  0.0433,  0.0203,  0.0206]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_weights = average_weights(local_weights)\n",
    "global_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=4096, bias=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if args.model == 'data2vec':\n",
    "    mask_time_prob = 0                                                          # change config to avoid training stopping\n",
    "    config = Data2VecAudioConfig.from_pretrained(args.pretrain_name, mask_time_prob=mask_time_prob)\n",
    "    model = Data2VecAudioForCTC.from_pretrained(args.model_in_path, config=config, args=args)\n",
    "                                                                                # load/initialize global model\n",
    "    model.config.ctc_zero_infinity = True                                       # to avoid inf values\n",
    "\n",
    "    global_model = copy.deepcopy(model.arbitrator)                              # only has global toggling network\n",
    "    if global_weights != None:                                                  # if given global_weights\n",
    "        global_model.load_state_dict(global_weights)                            # load it\n",
    "    #else:\n",
    "    #    # copy weights\n",
    "    #    global_weights = copy.deepcopy(global_model.state_dict())                       # save global weight\n",
    "    processor = Wav2Vec2Processor.from_pretrained(args.pretrain_name)\n",
    "    data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "else:\n",
    "    exit('Error: unrecognized model')\n",
    "\n",
    "# Set the model to train and send it to device.\n",
    "global_model.to(device)\n",
    "global_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[-0.0123,  0.0295,  0.0211,  ..., -0.0300,  0.0236,  0.0029],\n",
      "        [ 0.0174,  0.0111,  0.0379,  ...,  0.0432, -0.0009,  0.0588],\n",
      "        [-0.0086, -0.0458, -0.0061,  ...,  0.0018, -0.0037, -0.0036],\n",
      "        ...,\n",
      "        [ 0.0082, -0.0028, -0.0058,  ...,  0.0179, -0.0070, -0.0085],\n",
      "        [-0.0223, -0.0279,  0.0233,  ...,  0.0101,  0.0206,  0.0180],\n",
      "        [-0.0271,  0.0189,  0.0437,  ...,  0.0140, -0.0013,  0.0029]])), ('bias', tensor([0., 0., 0.,  ..., 0., 0., 0.]))])\n"
     ]
    }
   ],
   "source": [
    "w = global_model.state_dict()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', array([[-0.0123494 ,  0.02952368,  0.02109445, ..., -0.02995213,\n",
      "         0.02364982,  0.00286387],\n",
      "       [ 0.01744892,  0.01111791,  0.03789755, ...,  0.04320697,\n",
      "        -0.00092741,  0.05882485],\n",
      "       [-0.00859752, -0.04579691, -0.00612044, ...,  0.00179596,\n",
      "        -0.00365438, -0.00361218],\n",
      "       ...,\n",
      "       [ 0.00822815, -0.00279331, -0.00580185, ...,  0.01794216,\n",
      "        -0.00702918, -0.00849224],\n",
      "       [-0.02230225, -0.02785204,  0.02326177, ...,  0.01009476,\n",
      "         0.02058739,  0.01800553],\n",
      "       [-0.02707957,  0.01885535,  0.04367625, ...,  0.01396277,\n",
      "        -0.00133464,  0.00289201]], dtype=float32)), ('bias', array([0., 0., 0., ..., 0., 0., 0.], dtype=float32))])\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "w_ret = OrderedDict()\n",
    "w_ret['weight'] = w['weight'].numpy()\n",
    "w_ret['bias'] = w['bias'].numpy()\n",
    "print(w_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "print(w.cpu())\n",
    "#copy.deepcopy(w.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.0123,  0.0295,  0.0211,  ..., -0.0300,  0.0236,  0.0029],\n",
       "                      [ 0.0174,  0.0111,  0.0379,  ...,  0.0432, -0.0009,  0.0588],\n",
       "                      [-0.0086, -0.0458, -0.0061,  ...,  0.0018, -0.0037, -0.0036],\n",
       "                      ...,\n",
       "                      [ 0.0082, -0.0028, -0.0058,  ...,  0.0179, -0.0070, -0.0085],\n",
       "                      [-0.0223, -0.0279,  0.0233,  ...,  0.0101,  0.0206,  0.0180],\n",
       "                      [-0.0271,  0.0189,  0.0437,  ...,  0.0140, -0.0013,  0.0029]])),\n",
       "             ('bias', tensor([0., 0., 0.,  ..., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = multiprocessing.Manager()\n",
    "return_dict = manager.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict[2] = [global_model.state_dict(), 0.88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[OrderedDict([('weight',\n",
       "                tensor([[-0.0123,  0.0295,  0.0211,  ..., -0.0300,  0.0236,  0.0029],\n",
       "                        [ 0.0174,  0.0111,  0.0379,  ...,  0.0432, -0.0009,  0.0588],\n",
       "                        [-0.0086, -0.0458, -0.0061,  ...,  0.0018, -0.0037, -0.0036],\n",
       "                        ...,\n",
       "                        [ 0.0082, -0.0028, -0.0058,  ...,  0.0179, -0.0070, -0.0085],\n",
       "                        [-0.0223, -0.0279,  0.0233,  ...,  0.0101,  0.0206,  0.0180],\n",
       "                        [-0.0271,  0.0189,  0.0437,  ...,  0.0140, -0.0013,  0.0029]])),\n",
       "               ('bias', tensor([0., 0., 0.,  ..., 0., 0., 0.]))]),\n",
       "  0.88],\n",
       " [OrderedDict([('weight',\n",
       "                tensor([[-0.0123,  0.0295,  0.0211,  ..., -0.0300,  0.0236,  0.0029],\n",
       "                        [ 0.0174,  0.0111,  0.0379,  ...,  0.0432, -0.0009,  0.0588],\n",
       "                        [-0.0086, -0.0458, -0.0061,  ...,  0.0018, -0.0037, -0.0036],\n",
       "                        ...,\n",
       "                        [ 0.0082, -0.0028, -0.0058,  ...,  0.0179, -0.0070, -0.0085],\n",
       "                        [-0.0223, -0.0279,  0.0233,  ...,  0.0101,  0.0206,  0.0180],\n",
       "                        [-0.0271,  0.0189,  0.0437,  ...,  0.0140, -0.0013,  0.0029]])),\n",
       "               ('bias', tensor([0., 0., 0.,  ..., 0., 0., 0.]))]),\n",
       "  0.88]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_dict.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下尚未確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('weight',\n",
       "               tensor([[-0.0130,  0.0346,  0.0234,  ..., -0.0382,  0.0211,  0.0051],\n",
       "                       [ 0.0241,  0.0255,  0.0383,  ...,  0.0432,  0.0020,  0.0541],\n",
       "                       [-0.0088, -0.0451, -0.0152,  ...,  0.0060, -0.0079, -0.0027],\n",
       "                       ...,\n",
       "                       [-0.0066, -0.0090, -0.0239,  ...,  0.0724, -0.0043,  0.0117],\n",
       "                       [-0.0451, -0.0136,  0.0419,  ...,  0.0208,  0.0978,  0.0114],\n",
       "                       [-0.0099,  0.0023,  0.0220,  ...,  0.0394, -0.0133,  0.0624]],\n",
       "                      device='cuda:0')),\n",
       "              ('bias',\n",
       "               tensor([-0.0086, -0.0131,  0.0066,  ...,  0.0325, -0.0189,  0.0216],\n",
       "                      device='cuda:0'))]),\n",
       " OrderedDict([('weight',\n",
       "               tensor([[-0.0130,  0.0346,  0.0234,  ..., -0.0382,  0.0211,  0.0051],\n",
       "                       [ 0.0241,  0.0255,  0.0383,  ...,  0.0432,  0.0020,  0.0541],\n",
       "                       [-0.0088, -0.0451, -0.0152,  ...,  0.0060, -0.0079, -0.0027],\n",
       "                       ...,\n",
       "                       [-0.0066, -0.0090, -0.0239,  ...,  0.0724, -0.0043,  0.0117],\n",
       "                       [-0.0451, -0.0136,  0.0419,  ...,  0.0208,  0.0978,  0.0114],\n",
       "                       [-0.0099,  0.0023,  0.0220,  ...,  0.0394, -0.0133,  0.0624]],\n",
       "                      device='cuda:0')),\n",
       "              ('bias',\n",
       "               tensor([-0.0086, -0.0131,  0.0066,  ...,  0.0325, -0.0189,  0.0216],\n",
       "                      device='cuda:0'))])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.0130,  0.0346,  0.0234,  ..., -0.0382,  0.0211,  0.0051],\n",
       "                      [ 0.0241,  0.0255,  0.0383,  ...,  0.0432,  0.0020,  0.0541],\n",
       "                      [-0.0088, -0.0451, -0.0152,  ...,  0.0060, -0.0079, -0.0027],\n",
       "                      ...,\n",
       "                      [-0.0066, -0.0090, -0.0239,  ...,  0.0724, -0.0043,  0.0117],\n",
       "                      [-0.0451, -0.0136,  0.0419,  ...,  0.0208,  0.0978,  0.0114],\n",
       "                      [-0.0099,  0.0023,  0.0220,  ...,  0.0394, -0.0133,  0.0624]],\n",
       "                     device='cuda:0')),\n",
       "             ('bias',\n",
       "              tensor([-0.0086, -0.0131,  0.0066,  ...,  0.0325, -0.0189,  0.0216],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get global weights by averaging local weights\n",
    "global_weights = average_weights(local_weights)\n",
    "global_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[538.7666110436893]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update global weights\n",
    "global_model.load_state_dict(global_weights)\n",
    "\n",
    "loss_avg = sum(local_losses) / len(local_losses)                # average losses from participated client\n",
    "train_loss.append(loss_avg)     \n",
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/data2vec-audio-large-960h/resolve/main/config.json from cache at /home/weitung/.cache/huggingface/transformers/a5e291023d6dd7ec0034390cee6d97f07e340fb24c68c7b5f3ec8d017a6fd29d.ed9b9e83fb80348aa91a073138fc7a0f44e669fc412c9c4bc98857f45bfd4330\n",
      "Model config Data2VecAudioConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Data2VecAudioForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 768,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_pos_kernel_size\": 19,\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0,\n",
      "  \"model_type\": \"data2vec-audio\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 5,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 768,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading weights file /mnt/Internal/FedASR/weitung/HuggingFace/Pretrain/saves/data2vec-audio-large-960h_new1_recall/final/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load global!!!!!!!!!!!!! should change to client model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing Data2VecAudioForCTC_eval.\n",
      "\n",
      "All the weights of Data2VecAudioForCTC_eval were initialized from the model checkpoint at /mnt/Internal/FedASR/weitung/HuggingFace/Pretrain/saves/data2vec-audio-large-960h_new1_recall/final/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Data2VecAudioForCTC_eval for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n",
      "before:  OrderedDict([('weight', tensor([[-0.0123,  0.0295,  0.0211,  ..., -0.0300,  0.0236,  0.0029],\n",
      "        [ 0.0174,  0.0111,  0.0379,  ...,  0.0432, -0.0009,  0.0588],\n",
      "        [-0.0086, -0.0458, -0.0061,  ...,  0.0018, -0.0037, -0.0036],\n",
      "        ...,\n",
      "        [ 0.0082, -0.0028, -0.0058,  ...,  0.0179, -0.0070, -0.0085],\n",
      "        [-0.0223, -0.0279,  0.0233,  ...,  0.0101,  0.0206,  0.0180],\n",
      "        [-0.0271,  0.0189,  0.0437,  ...,  0.0140, -0.0013,  0.0029]])), ('bias', tensor([0., 0., 0.,  ..., 0., 0., 0.]))])\n",
      "after:  OrderedDict([('weight', tensor([[-0.0130,  0.0346,  0.0234,  ..., -0.0382,  0.0211,  0.0051],\n",
      "        [ 0.0241,  0.0255,  0.0383,  ...,  0.0432,  0.0020,  0.0541],\n",
      "        [-0.0088, -0.0451, -0.0152,  ...,  0.0060, -0.0079, -0.0027],\n",
      "        ...,\n",
      "        [-0.0066, -0.0090, -0.0239,  ...,  0.0724, -0.0043,  0.0117],\n",
      "        [-0.0451, -0.0136,  0.0419,  ...,  0.0208,  0.0978,  0.0114],\n",
      "        [-0.0099,  0.0023,  0.0220,  ...,  0.0394, -0.0133,  0.0624]])), ('bias', tensor([-0.0086, -0.0131,  0.0066,  ...,  0.0325, -0.0189,  0.0216]))])\n",
      "798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/data2vec-audio-large-960h/resolve/main/config.json from cache at /home/weitung/.cache/huggingface/transformers/a5e291023d6dd7ec0034390cee6d97f07e340fb24c68c7b5f3ec8d017a6fd29d.ed9b9e83fb80348aa91a073138fc7a0f44e669fc412c9c4bc98857f45bfd4330\n",
      "Model config Data2VecAudioConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Data2VecAudioForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 768,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_pos_kernel_size\": 19,\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0,\n",
      "  \"model_type\": \"data2vec-audio\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 5,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 768,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading weights file /mnt/Internal/FedASR/weitung/HuggingFace/Pretrain/saves/data2vec-audio-large-960h_new1_recall/final/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load global!!!!!!!!!!!!! should change to client model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing Data2VecAudioForCTC_eval.\n",
      "\n",
      "All the weights of Data2VecAudioForCTC_eval were initialized from the model checkpoint at /mnt/Internal/FedASR/weitung/HuggingFace/Pretrain/saves/data2vec-audio-large-960h_new1_recall/final/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Data2VecAudioForCTC_eval for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n",
      "before:  OrderedDict([('weight', tensor([[-0.0123,  0.0295,  0.0211,  ..., -0.0300,  0.0236,  0.0029],\n",
      "        [ 0.0174,  0.0111,  0.0379,  ...,  0.0432, -0.0009,  0.0588],\n",
      "        [-0.0086, -0.0458, -0.0061,  ...,  0.0018, -0.0037, -0.0036],\n",
      "        ...,\n",
      "        [ 0.0082, -0.0028, -0.0058,  ...,  0.0179, -0.0070, -0.0085],\n",
      "        [-0.0223, -0.0279,  0.0233,  ...,  0.0101,  0.0206,  0.0180],\n",
      "        [-0.0271,  0.0189,  0.0437,  ...,  0.0140, -0.0013,  0.0029]])), ('bias', tensor([0., 0., 0.,  ..., 0., 0., 0.]))])\n",
      "after:  OrderedDict([('weight', tensor([[-0.0130,  0.0346,  0.0234,  ..., -0.0382,  0.0211,  0.0051],\n",
      "        [ 0.0241,  0.0255,  0.0383,  ...,  0.0432,  0.0020,  0.0541],\n",
      "        [-0.0088, -0.0451, -0.0152,  ...,  0.0060, -0.0079, -0.0027],\n",
      "        ...,\n",
      "        [-0.0066, -0.0090, -0.0239,  ...,  0.0724, -0.0043,  0.0117],\n",
      "        [-0.0451, -0.0136,  0.0419,  ...,  0.0208,  0.0978,  0.0114],\n",
      "        [-0.0099,  0.0023,  0.0220,  ...,  0.0394, -0.0133,  0.0624]])), ('bias', tensor([-0.0086, -0.0131,  0.0066,  ...,  0.0325, -0.0189,  0.0216]))])\n",
      "798"
     ]
    }
   ],
   "source": [
    "list_wer = []\n",
    "global_model.eval()\n",
    "for c in range(args.num_users):                                 # for ALL users\n",
    "    local_model = ASRLocalUpdate(args=args, dataset=train_dataset, logger=logger,\n",
    "                        data_collator=data_collator, global_test_dataset=test_dataset, \n",
    "                        processor=processor)\n",
    "                                                                # initial dataset of current client\n",
    "    wer = local_model.inference(global_arbitrator=global_model)       # get acc. & total loss on clients' test set\n",
    "    list_wer.append(wer)                                        # save acc.\n",
    "    #list_loss.append(loss)                                      # save loss\n",
    "train_accuracy.append(sum(list_wer)/len(list_wer))              # acc average over all clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下尚未確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Avg Training Stats after 2 global rounds:\n",
      "Training Loss : 538.7666110436893\n",
      "Train Accuracy: 25.77% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# print global training loss after every 'i' rounds\n",
    "if (1+1) % print_every == 0:\n",
    "    print(f' \\nAvg Training Stats after {1+1} global rounds:')\n",
    "    print(f'Training Loss : {np.mean(np.array(train_loss))}')\n",
    "    print('Train Accuracy: {:.2f}% \\n'.format(100*train_accuracy[-1])) # on testing set of clients though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using amp half precision backend\n",
      "The following columns in the training set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: array, text, path. If array, text, path are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 1868\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3736' max='3736' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3736/3736 15:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>7.110900</td>\n",
       "      <td>5.394214</td>\n",
       "      <td>0.259387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.298200</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.259230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.970600</td>\n",
       "      <td>1.098743</td>\n",
       "      <td>0.259230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.122200</td>\n",
       "      <td>1.066993</td>\n",
       "      <td>0.259230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.041327</td>\n",
       "      <td>0.260644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.150100</td>\n",
       "      <td>1.019284</td>\n",
       "      <td>0.257816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.025900</td>\n",
       "      <td>1.029965</td>\n",
       "      <td>0.258602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: array, text, path. If array, text, path are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-500\n",
      "Configuration saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-500/config.json\n",
      "Model weights saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-500/pytorch_model.bin\n",
      "Feature extractor saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-500/preprocessor_config.json\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: array, text, path. If array, text, path are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-1000\n",
      "Configuration saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-1000/config.json\n",
      "Model weights saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-1000/pytorch_model.bin\n",
      "Feature extractor saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-1000/preprocessor_config.json\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: array, text, path. If array, text, path are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-1500\n",
      "Configuration saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-1500/config.json\n",
      "Model weights saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-1500/pytorch_model.bin\n",
      "Feature extractor saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-1500/preprocessor_config.json\n",
      "Deleting older checkpoint [saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: array, text, path. If array, text, path are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-2000\n",
      "Configuration saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-2000/config.json\n",
      "Model weights saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-2000/pytorch_model.bin\n",
      "Feature extractor saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-2000/preprocessor_config.json\n",
      "Deleting older checkpoint [saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-1000] due to args.save_total_limit\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: array, text, path. If array, text, path are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-2500\n",
      "Configuration saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-2500/config.json\n",
      "Model weights saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-2500/pytorch_model.bin\n",
      "Feature extractor saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-2500/preprocessor_config.json\n",
      "Deleting older checkpoint [saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-1500] due to args.save_total_limit\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: array, text, path. If array, text, path are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-3000\n",
      "Configuration saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-3000/config.json\n",
      "Model weights saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-3000/pytorch_model.bin\n",
      "Feature extractor saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-3000/preprocessor_config.json\n",
      "Deleting older checkpoint [saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-2000] due to args.save_total_limit\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `Data2VecAudioForCTC.forward` and have been ignored: array, text, path. If array, text, path are not expected by `Data2VecAudioForCTC.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-3500\n",
      "Configuration saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-3500/config.json\n",
      "Model weights saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-3500/pytorch_model.bin\n",
      "Feature extractor saved in ./saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-3500/preprocessor_config.json\n",
      "Deleting older checkpoint [saves/wav2vec2-base-960h_linear_GRLjust_for_testing/checkpoint-2500] due to args.save_total_limit\n",
      "/home/weitung/.conda/envs/flwr-huggingface/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n",
      "loss: cel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3736, training_loss=2.053420505891265, metrics={'train_runtime': 905.8756, 'train_samples_per_second': 4.124, 'train_steps_per_second': 4.124, 'total_flos': 4.252288675625975e+17, 'train_loss': 2.053420505891265, 'epoch': 2.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.training_args import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "import json\n",
    "\n",
    "LOG_DIR = './'#log/'\n",
    "from datasets import load_metric\n",
    "wer_metric = load_metric(\"wer\")\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}\n",
    "\n",
    "class CustomTrainer(Trainer):    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "            \"\"\"\n",
    "            How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
    "            Subclass and override for custom behavior.\n",
    "            \"\"\"\n",
    "            #dementia_labels = inputs.pop(\"dementia_labels\") # pop 出來就會不見?\n",
    "            \n",
    "            if self.label_smoother is not None and \"labels\" in inputs:\n",
    "                labels = inputs.pop(\"labels\")\n",
    "            else:\n",
    "                labels = None\n",
    "            \n",
    "            outputs = model(**inputs)\n",
    "            # Save past state if it exists\n",
    "            # TODO: this needs to be fixed and made cleaner later.\n",
    "            if self.args.past_index >= 0:\n",
    "                self._past = outputs[self.args.past_index]\n",
    "\n",
    "            if labels is not None:\n",
    "                loss = self.label_smoother(outputs, labels)\n",
    "            else:\n",
    "                # We don't use .loss here since the model may return tuples instead of ModelOutput.\n",
    "                loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
    "\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "    def log(self, logs: Dict[str, float]) -> None:\n",
    "        \"\"\"\n",
    "        Log `logs` on the various objects watching training.\n",
    "        Subclass and override this method to inject custom behavior.\n",
    "        Args:\n",
    "            logs (`Dict[str, float]`):\n",
    "                The values to log.\n",
    "        \"\"\"\n",
    "        if self.state.epoch is not None:\n",
    "            logs[\"epoch\"] = round(self.state.epoch, 2)\n",
    "\n",
    "        output = {**logs, **{\"step\": self.state.global_step}}\n",
    "        self.state.log_history.append(output)\n",
    "        \n",
    "        # write to txt file\n",
    "        file_object = open(LOG_DIR + args.log_path, 'a')\n",
    "        # Append at the end of file\n",
    "        file_object.write(json.dumps(output) + '\\n')\n",
    "        # Close the file\n",
    "        file_object.close()\n",
    "\n",
    "        self.control = self.callback_handler.on_log(self.args, self.state, self.control, logs)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=args.model_out_path + \"just_for_testing\",\n",
    "    group_by_length=True,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=2,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True, \n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    logging_steps=500,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.005,\n",
    "    warmup_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    log_level='debug',\n",
    "    logging_strategy=\"steps\",\n",
    "    #adafactor=True,            # default:false. Whether or not to use transformers.Adafactor optimizer instead of transformers.AdamW\n",
    "    #fp16_full_eval=True,      # to save memory\n",
    "    #max_grad_norm=0.5\n",
    ")\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.0123,  0.0295,  0.0211,  ..., -0.0300,  0.0236,  0.0029],\n",
       "                      [ 0.0174,  0.0111,  0.0379,  ...,  0.0432, -0.0009,  0.0588],\n",
       "                      [-0.0086, -0.0458, -0.0061,  ...,  0.0018, -0.0037, -0.0036],\n",
       "                      ...,\n",
       "                      [ 0.0082, -0.0028, -0.0058,  ...,  0.0179, -0.0070, -0.0085],\n",
       "                      [-0.0223, -0.0279,  0.0233,  ...,  0.0101,  0.0206,  0.0180],\n",
       "                      [-0.0271,  0.0189,  0.0437,  ...,  0.0140, -0.0013,  0.0029]],\n",
       "                     device='cuda:0')),\n",
       "             ('bias',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.arbitrator.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 7.1109, 'learning_rate': 4.99e-05, 'epoch': 0.27, 'step': 500},\n",
       " {'eval_loss': 5.394213676452637,\n",
       "  'eval_wer': 0.2593872741555381,\n",
       "  'eval_runtime': 75.9333,\n",
       "  'eval_samples_per_second': 10.536,\n",
       "  'eval_steps_per_second': 10.536,\n",
       "  'epoch': 0.27,\n",
       "  'step': 500},\n",
       " {'loss': 2.2982, 'learning_rate': 9.99e-05, 'epoch': 0.54, 'step': 1000},\n",
       " {'eval_loss': 0.7303922772407532,\n",
       "  'eval_wer': 0.25923016496465046,\n",
       "  'eval_runtime': 75.0628,\n",
       "  'eval_samples_per_second': 10.658,\n",
       "  'eval_steps_per_second': 10.658,\n",
       "  'epoch': 0.54,\n",
       "  'step': 1000},\n",
       " {'loss': 0.9706,\n",
       "  'learning_rate': 8.176169590643276e-05,\n",
       "  'epoch': 0.8,\n",
       "  'step': 1500},\n",
       " {'eval_loss': 1.0987427234649658,\n",
       "  'eval_wer': 0.25923016496465046,\n",
       "  'eval_runtime': 75.0833,\n",
       "  'eval_samples_per_second': 10.655,\n",
       "  'eval_steps_per_second': 10.655,\n",
       "  'epoch': 0.8,\n",
       "  'step': 1500},\n",
       " {'loss': 1.1222,\n",
       "  'learning_rate': 6.348684210526316e-05,\n",
       "  'epoch': 1.07,\n",
       "  'step': 2000},\n",
       " {'eval_loss': 1.0669927597045898,\n",
       "  'eval_wer': 0.25923016496465046,\n",
       "  'eval_runtime': 75.6443,\n",
       "  'eval_samples_per_second': 10.576,\n",
       "  'eval_steps_per_second': 10.576,\n",
       "  'epoch': 1.07,\n",
       "  'step': 2000},\n",
       " {'loss': 1.1327,\n",
       "  'learning_rate': 4.524853801169591e-05,\n",
       "  'epoch': 1.34,\n",
       "  'step': 2500},\n",
       " {'eval_loss': 1.0413274765014648,\n",
       "  'eval_wer': 0.26064414768263944,\n",
       "  'eval_runtime': 75.6587,\n",
       "  'eval_samples_per_second': 10.574,\n",
       "  'eval_steps_per_second': 10.574,\n",
       "  'epoch': 1.34,\n",
       "  'step': 2500},\n",
       " {'loss': 1.1501,\n",
       "  'learning_rate': 2.6973684210526317e-05,\n",
       "  'epoch': 1.61,\n",
       "  'step': 3000},\n",
       " {'eval_loss': 1.0192844867706299,\n",
       "  'eval_wer': 0.2578161822466614,\n",
       "  'eval_runtime': 75.4,\n",
       "  'eval_samples_per_second': 10.61,\n",
       "  'eval_steps_per_second': 10.61,\n",
       "  'epoch': 1.61,\n",
       "  'step': 3000},\n",
       " {'loss': 1.0259,\n",
       "  'learning_rate': 8.698830409356726e-06,\n",
       "  'epoch': 1.87,\n",
       "  'step': 3500},\n",
       " {'eval_loss': 1.029964804649353,\n",
       "  'eval_wer': 0.2586017282010998,\n",
       "  'eval_runtime': 75.6327,\n",
       "  'eval_samples_per_second': 10.577,\n",
       "  'eval_steps_per_second': 10.577,\n",
       "  'epoch': 1.87,\n",
       "  'step': 3500},\n",
       " {'train_runtime': 905.8756,\n",
       "  'train_samples_per_second': 4.124,\n",
       "  'train_steps_per_second': 4.124,\n",
       "  'total_flos': 4.252288675625975e+17,\n",
       "  'train_loss': 2.053420505891265,\n",
       "  'epoch': 2.0,\n",
       "  'step': 3736}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.053420505891265"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history[-1][\"train_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(args.epochs)):\n",
    "    local_weights, local_losses = [], []\n",
    "    print(f'\\n | Global Training Round : {epoch+1} |\\n') # epoch = round\n",
    "\n",
    "    global_model.train()\n",
    "    m = max(int(args.frac * args.num_users), 1) # 取部分client來train，至少一個client\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False) # 選client_id\n",
    "\n",
    "    for idx in idxs_users: # 每一位選上的client\n",
    "        # 做training?\n",
    "        local_model = LocalUpdate(args=args, dataset=train_dataset,\n",
    "                                    idxs=user_groups[idx], logger=logger)\n",
    "        # 得到這次的weights + loss\n",
    "        w, loss = local_model.update_weights(\n",
    "            model=copy.deepcopy(global_model), global_round=epoch)\n",
    "        local_weights.append(copy.deepcopy(w))\n",
    "        local_losses.append(copy.deepcopy(loss))\n",
    "\n",
    "    # compute global weights\n",
    "    global_weights = average_weights(local_weights)\n",
    "\n",
    "    # update global weights\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    loss_avg = sum(local_losses) / len(local_losses)\n",
    "    train_loss.append(loss_avg) # loss average over all clients\n",
    "\n",
    "    # Calculate avg training accuracy over all users at every epoch\n",
    "    list_acc, list_loss = [], []\n",
    "    global_model.eval()\n",
    "    for c in range(args.num_users): # 所有clients\n",
    "        # 做training? 應為update weight\n",
    "        local_model = LocalUpdate(args=args, dataset=train_dataset,\n",
    "                                    idxs=user_groups[idx], logger=logger)\n",
    "        # 用global model去測試，得到acc & loss\n",
    "        acc, loss = local_model.inference(model=global_model)\n",
    "        list_acc.append(acc)\n",
    "        list_loss.append(loss)\n",
    "    train_accuracy.append(sum(list_acc)/len(list_acc)) # acc_avg\n",
    "\n",
    "    # print global training loss after every 'i' rounds\n",
    "    if (epoch+1) % print_every == 0:\n",
    "        print(f' \\nAvg Training Stats after {epoch+1} global rounds:')\n",
    "        print(f'Training Loss : {np.mean(np.array(train_loss))}')\n",
    "        print('Train Accuracy: {:.2f}% \\n'.format(100*train_accuracy[-1]))\n",
    "\n",
    "# Test inference after completion of training\n",
    "test_acc, test_loss = test_inference(args, global_model, test_dataset)\n",
    "\n",
    "print(f' \\n Results after {args.epochs} global rounds of training:')\n",
    "print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100*train_accuracy[-1]))\n",
    "print(\"|---- Test Accuracy: {:.2f}%\".format(100*test_acc))\n",
    "\n",
    "# Saving the objects train_loss and train_accuracy:\n",
    "file_name = '../save/objects/{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}].pkl'.\\\n",
    "    format(args.dataset, args.model, args.epochs, args.frac, args.iid,\n",
    "            args.local_ep, args.local_bs)\n",
    "\n",
    "# save 失敗\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump([train_loss, train_accuracy], f)\n",
    "\n",
    "print('\\n Total Run Time: {0:0.4f}'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
