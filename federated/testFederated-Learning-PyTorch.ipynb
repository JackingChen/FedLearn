{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from options import args_parser\n",
    "from update import LocalUpdate, test_inference, ASRLocalUpdate\n",
    "from models import MLP, CNNMnist, CNNFashion_Mnist, CNNCifar, Data2VecAudioForCTC, DataCollatorCTCWithPadding\n",
    "from utils import get_dataset, average_weights, exp_details\n",
    "\n",
    "from transformers import Data2VecAudioConfig, Wav2Vec2Processor\n",
    "from multiprocessing import Pool\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import argparse\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# federated arguments (Notation for the arguments followed from paper)\n",
    "parser.add_argument('--epochs', type=int, default=2,\n",
    "                    help=\"number of rounds of training\")\n",
    "parser.add_argument('--num_users', type=int, default=2,\n",
    "                    help=\"number of users: K\")\n",
    "parser.add_argument('--frac', type=float, default=1.0,\n",
    "                    help='the fraction of clients: C')\n",
    "parser.add_argument('--local_ep', type=int, default=1,\n",
    "                    help=\"the number of local epochs: E\")\n",
    "#parser.add_argument('--local_bs', type=int, default=1,\n",
    "#                    help=\"local batch size: B\")\n",
    "#parser.add_argument('--lr', type=float, default=0.01,\n",
    "#                    help='learning rate')\n",
    "#parser.add_argument('--momentum', type=float, default=0.5,\n",
    "#                    help='SGD momentum (default: 0.5)')\n",
    "\n",
    "# model arguments\n",
    "parser.add_argument('--model', type=str, default='data2vec', help='model name')\n",
    "#parser.add_argument('--kernel_num', type=int, default=9,\n",
    "#                    help='number of each kind of kernel')\n",
    "#parser.add_argument('--kernel_sizes', type=str, default='3,4,5',\n",
    "#                    help='comma-separated kernel size to \\\n",
    "#                    use for convolution')\n",
    "#parser.add_argument('--num_channels', type=int, default=1, help=\"number \\\n",
    "#                    of channels of imgs\")\n",
    "#parser.add_argument('--norm', type=str, default='batch_norm',\n",
    "#                    help=\"batch_norm, layer_norm, or None\")\n",
    "#parser.add_argument('--num_filters', type=int, default=32,\n",
    "#                    help=\"number of filters for conv nets -- 32 for \\\n",
    "#                    mini-imagenet, 64 for omiglot.\")\n",
    "#parser.add_argument('--max_pool', type=str, default='True',\n",
    "#                    help=\"Whether use max pooling rather than \\\n",
    "#                    strided convolutions\")\n",
    "\n",
    "# other arguments\n",
    "parser.add_argument('--dataset', type=str, default='adress', help=\"name \\\n",
    "                    of dataset\") #cifar\n",
    "#parser.add_argument('--num_classes', type=int, default=10, help=\"number \\\n",
    "#                    of classes\")\n",
    "parser.add_argument('--gpu', default=1, help=\"To use cuda, set \\\n",
    "                    to a specific GPU ID. Default set to use CPU.\")\n",
    "#parser.add_argument('--optimizer', type=str, default='sgd', help=\"type \\\n",
    "#                    of optimizer\")\n",
    "#parser.add_argument('--iid', type=int, default=1,\n",
    "#                    help='Default set to IID. Set to 0 for non-IID.')\n",
    "#parser.add_argument('--unequal', type=int, default=0,\n",
    "#                    help='whether to use unequal data splits for  \\\n",
    "#                    non-i.i.d setting (use 0 for equal splits)')\n",
    "#parser.add_argument('--stopping_rounds', type=int, default=10,\n",
    "#                    help='rounds of early stopping')\n",
    "#parser.add_argument('--verbose', type=int, default=1, help='verbose')\n",
    "#parser.add_argument('--seed', type=int, default=1, help='random seed')\n",
    "\n",
    "# additional arguments\n",
    "parser.add_argument('--pretrain_name', type=str, default='facebook/data2vec-audio-large-960h', help=\"str used to load pretrain model\")\n",
    "parser.add_argument('-lam', '--LAMBDA', type=float, default=0.5, help=\"Lambda for GRL\")\n",
    "parser.add_argument('-st', '--STAGE', type=int, default=2, help=\"Current training stage\")\n",
    "parser.add_argument('-GRL', '--GRL', action='store_true', default=False, help=\"True: GRL\")\n",
    "parser.add_argument('-model_in', '--model_in_path', type=str, default=\"/mnt/Internal/FedASR/weitung/HuggingFace/Pretrain/saves/data2vec-audio-large-960h_new1_recall/final/\", help=\"Where the model is saved\")\n",
    "parser.add_argument('-model_out', '--model_out_path', type=str, default=\"./save/data2vec-audio-large-960h_new2_recall_FL\", help=\"Where to save the model\")\n",
    "parser.add_argument('-log', '--log_path', type=str, default=\"data2vec-audio-large-960h_new2_recall_FL.txt\", help=\"name for the txt file\")\n",
    "# 2023/01/08: loss type\n",
    "parser.add_argument('-ad_loss', '--AD_loss', type=str, default=\"recall\", help=\"loss to use for AD classifier\")\n",
    "# 2023/01/18: ckpt\n",
    "parser.add_argument('-ckpt', '--checkpoint', type=str, default=None, help=\"path to checkpoint\")\n",
    "# 2023/02/13: TOGGLE_RATIO\n",
    "parser.add_argument('-toggle_rt', '--TOGGLE_RATIO', type=float, default=0, help=\"To toggle more or less\")\n",
    "# 2023/02/15: GS_TAU, loss weight\n",
    "parser.add_argument('-gs_tau', '--GS_TAU', type=float, default=1, help=\"Tau for gumbel_softmax\")\n",
    "parser.add_argument('-w_loss', '--W_LOSS', type=float, default=None, nargs='+', help=\"weight for HC and AD\")\n",
    "\n",
    "args = parser.parse_args(args=[]) # for jupyter notebook\n",
    "\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\" # 或者其他你想要使用的 GPU 編號\n",
    "# 創建一個 Lock 對象\n",
    "lock = mp.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def client_train(args, train_dataset, \n",
    "                 test_dataset, idx, epoch, global_weights=None):                    # train function for each client\n",
    "    print(\" process PID\", os.getpid(), \" running\")\n",
    "    \n",
    "    # BUILD MODEL for every process\n",
    "    if args.model == 'data2vec':\n",
    "        mask_time_prob = 0                                                          # change config to avoid training stopping\n",
    "        config = Data2VecAudioConfig.from_pretrained(args.pretrain_name, mask_time_prob=mask_time_prob)\n",
    "        print(\"load from \", args.model_in_path)\n",
    "        lock.acquire()\n",
    "        # print(\" process PID\", os.getpid(),\"enter critical section\")\n",
    "        # model = Data2VecAudioForCTC.from_pretrained(args.model_in_path, config=config, args=args)\n",
    "        # lock.release()\n",
    "        # print(\" process PID\", os.getpid(),\"exit critical section\")\n",
    "        try:\n",
    "            # 在這裡執行 critical section 的程式碼\n",
    "            print(\" process PID\", os.getpid(),\"enter critical section\")\n",
    "            model = Data2VecAudioForCTC.from_pretrained(args.model_in_path, config=config, args=args)\n",
    "            pass\n",
    "        finally:\n",
    "            # 在離開 critical section 後釋放鎖\n",
    "            lock.release()\n",
    "            print(\" process PID\", os.getpid(),\"exit critical section\")\n",
    "        print(\"model loaded\")                                                       # load/initialize global model\n",
    "        model.config.ctc_zero_infinity = True                                       # to avoid inf values\n",
    "\n",
    "        global_model = copy.deepcopy(model.arbitrator)                              # only has global toggling network\n",
    "        if global_weights != None:                                                  # if given global_weights\n",
    "            global_model.load_state_dict(global_weights)                            # load it\n",
    "        #else:\n",
    "        #    # copy weights\n",
    "        #    global_weights = copy.deepcopy(global_model.state_dict())                       # save global weight\n",
    "        processor = Wav2Vec2Processor.from_pretrained(args.pretrain_name)\n",
    "        data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "    else:\n",
    "        exit('Error: unrecognized model')\n",
    "\n",
    "    # Set the model to train and send it to device.\n",
    "    device = 'cuda' if args.gpu else 'cpu'\n",
    "    global_model.to(device)\n",
    "    global_model.train()\n",
    "    #print(global_model)\n",
    "\n",
    "    ####################\n",
    "    # 'use client_id generate sub-dataset' to be done\n",
    "    ####################\n",
    "    #print(\"call ASRLocalUpdate\")\n",
    "    local_model = ASRLocalUpdate(args=args, dataset=train_dataset, logger=logger,\n",
    "                        data_collator=data_collator, global_test_dataset=test_dataset, \n",
    "                        processor=processor, client_id=idx)\n",
    "                                                                                    # initial dataset of current client\n",
    "    ####################\n",
    "    # 'use client_id load local model' to be done\n",
    "    # 'save model in final round' to be done\n",
    "    ####################\n",
    "    #print(\"perform update_weight\")\n",
    "    w, loss = local_model.update_weights(\n",
    "        global_arbitrator=copy.deepcopy(global_model), global_round=epoch)          # from global model to train\n",
    "    \n",
    "    #send_end.send([w, loss])                                                        # save model weights and average round loss\n",
    "    #return_dict[str(idx)] = [w, loss]\n",
    "    print(\"PID {} Getting \".format(os.getpid()), \"Done\")\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_get_weight(args, idx, epoch):                               # function to get weight for each client\n",
    "    print(\" process PID\", os.getpid(), \" running\")\n",
    "    # model saved in args.model_out_path + \"_\" + str(idx) + \"/final_\" + str(epoch)\n",
    "    #model_path = args.model_out_path + \"_\" + str(idx) + \"/final_\" + str(epoch)\n",
    "    #model_path = args.model_out_path + \"_client\" + str(idx) + \n",
    "    #\"_round\" + str(global_round) + \"/final\"\n",
    "    model_path = args.model_in_path\n",
    "    # BUILD MODEL for every process\n",
    "    if args.model == 'data2vec':\n",
    "        mask_time_prob = 0                                                          # change config to avoid training stopping\n",
    "        config = Data2VecAudioConfig.from_pretrained(args.pretrain_name, mask_time_prob=mask_time_prob)\n",
    "        model = Data2VecAudioForCTC.from_pretrained(model_path, config=config, args=args)\n",
    "                                                                                    # load local model\n",
    "        print(\"model loaded\")\n",
    "        model.config.ctc_zero_infinity = True                                       # to avoid inf values\n",
    " \n",
    "        arbitrator = copy.deepcopy(model.arbitrator)                                # return weight for toggling network only\n",
    "\n",
    "        return_weights = copy.deepcopy(arbitrator.state_dict())                       # save global weight\n",
    "    else:\n",
    "        exit('Error: unrecognized model')\n",
    "\n",
    "    #return_dict[str(idx)] = return_weights\n",
    "    print(\"PID {} Getting \".format(os.getpid()), \"Done\")\n",
    "    return return_weights, 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = time.time()\n",
    "\n",
    "# define paths\n",
    "#path_project = os.path.abspath('..')\n",
    "logger = SummaryWriter('../logs')\n",
    "\n",
    "#args = args_parser()\n",
    "exp_details(args) # print out details based on configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if args.gpu_id:\n",
    "#    torch.cuda.set_device(args.gpu_id)\n",
    "#device = 'cuda' if args.gpu else 'cpu'\n",
    "\n",
    "# load dataset and user groups\n",
    "train_dataset, test_dataset, user_groups = get_dataset(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID相關code先跳過"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_IDs = train_dataset.map(lambda x: {\"user_IDs\": x[\"path\"].split(\"_\")[0]})\n",
    "user_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = user_IDs[\"user_IDs\"]\n",
    "mylist = list(dict.fromkeys(mylist))\n",
    "print(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sub- training set for given user-ID\n",
    "start_with_ar = train_dataset.filter(lambda example: (example[\"path\"].startswith(\"S055\")) or (example[\"path\"].startswith(\"S094\")))\n",
    "start_with_ar[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar_iid(dataset, num_users):\n",
    "    \"\"\"\n",
    "    Sample I.I.D. client data from CIFAR10 dataset\n",
    "    :param dataset:\n",
    "    :param num_users:\n",
    "    :return: dict of image index\n",
    "    \"\"\"\n",
    "    num_items = int(len(dataset)/num_users)\n",
    "    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n",
    "    for i in range(num_users):\n",
    "        dict_users[i] = set(np.random.choice(all_idxs, num_items,\n",
    "                                             replace=False))\n",
    "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
    "    return dict_users\n",
    "def cifar_noniid(dataset, num_users):\n",
    "    \"\"\"\n",
    "    Sample non-I.I.D client data from CIFAR10 dataset\n",
    "    :param dataset:\n",
    "    :param num_users:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    num_shards, num_imgs = 200, 250\n",
    "    idx_shard = [i for i in range(num_shards)]\n",
    "    dict_users = {i: np.array([]) for i in range(num_users)}\n",
    "    idxs = np.arange(num_shards*num_imgs)\n",
    "    # labels = dataset.train_labels.numpy()\n",
    "    labels = np.array(dataset.train_labels)\n",
    "\n",
    "    # sort labels\n",
    "    idxs_labels = np.vstack((idxs, labels))\n",
    "    idxs_labels = idxs_labels[:, idxs_labels[1, :].argsort()]\n",
    "    idxs = idxs_labels[0, :]\n",
    "\n",
    "    # divide and assign\n",
    "    for i in range(num_users):\n",
    "        rand_set = set(np.random.choice(idx_shard, 2, replace=False))\n",
    "        idx_shard = list(set(idx_shard) - rand_set)\n",
    "        for rand in rand_set:\n",
    "            dict_users[i] = np.concatenate(\n",
    "                (dict_users[i], idxs[rand*num_imgs:(rand+1)*num_imgs]), axis=0)\n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面開始繼續跑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [參考](https://stackoverflow.com/questions/10415028/how-to-get-the-return-value-of-a-function-passed-to-multiprocessing-process): 不同multi-process寫法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-process ver1\n",
    "from multiprocessing import Pool\n",
    "\"\"\"\n",
    "def Get_phonationdictbag_map(parameters):\n",
    "    args, train_dataset, logger, test_dataset, idx, epoch, global_weights = parameters\n",
    "    print(\" process PID\", os.getpid(), \" running\")\n",
    "    for file in files:\n",
    "        ///\n",
    "        your code\n",
    "        ///\n",
    "    print(\"PID {} Getting \".format(os.getpid()), \"Done\")\n",
    "client_train(args, train_dataset, logger, \n",
    "                 test_dataset, idx, epoch, global_weights=None)\n",
    "\"\"\"\n",
    "#interval=20\n",
    "#parameters_lst = []\n",
    "#for i in range(args.num_users):                       # for each client\n",
    "    \n",
    "#    keys.append(files[i:i+interval])\n",
    "#flat_keys=[item for sublist in keys for item in sublist]\n",
    "#assert len(flat_keys) == len(files)\n",
    "\n",
    "#final_result = pool.starmap(Get_phonationdictbag_map, [([file_block])    for file_block in tqdm(keys)])\n",
    "#client_get_weight(args, idx, epoch)\n",
    "pool = Pool(int(os.cpu_count()))\n",
    "epoch = 0\n",
    "final_result = pool.starmap(client_get_weight, [(args, idx, epoch) for idx in range(args.num_users)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result[1]\n",
    "aaa=ccc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 只跑一個round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "train_loss, test_wer = [], []\n",
    "val_acc_list, net_list = [], []\n",
    "cv_loss, cv_acc = [], []\n",
    "print_every = 2\n",
    "val_loss_pre, counter = 0, 0\n",
    "global_weights = None                                                           # initial global_weights\n",
    "epoch = 0\n",
    "#for epoch in tqdm(range(args.epochs)):                                          # train for given global rounds\n",
    "#local_weights, local_losses = [], []                                        # weights and losses of training clients of this round\n",
    "print(f'\\n | Global Training Round : {epoch+1} |\\n')                        # print current round\n",
    "\n",
    "m = max(int(args.frac * args.num_users), 1)                                 # num of clients to train, min:1\n",
    "idxs_users = np.random.choice(range(args.num_users), m, replace=False)      # select by client_id\n",
    "\n",
    "pool = Pool(4)\n",
    "# pool = Pool(int(os.cpu_count()))\n",
    "import concurrent.futures\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    try:\n",
    "        final_result = pool.starmap(client_train, [(args, train_dataset, \n",
    "                        test_dataset, idx, epoch, global_weights) for idx in idxs_users])\n",
    "    except Exception as e:\n",
    "            # 处理子进程中的异常\n",
    "            print(f\"Exception in subprocess: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_weights = []\n",
    "local_losses = []\n",
    "for idx in range(len(final_result)):\n",
    "    w, loss = final_result[idx]\n",
    "    local_weights.append(w)\n",
    "    local_losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_weights = average_weights(local_weights)\n",
    "global_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool.close()\n",
    "# pool.terminate()\n",
    "\n",
    "epoch = 1\n",
    "#for epoch in tqdm(range(args.epochs)):                                          # train for given global rounds\n",
    "#local_weights, local_losses = [], []                                        # weights and losses of training clients of this round\n",
    "print(f'\\n | Global Training Round : {epoch+1} |\\n')                        # print current round\n",
    "\n",
    "m = max(int(args.frac * args.num_users), 1)                                 # num of clients to train, min:1\n",
    "idxs_users = np.random.choice(range(args.num_users), m, replace=False)      # select by client_id\n",
    "\n",
    "pool = Pool(4)\n",
    "final_result = pool.starmap(client_train, [(args, train_dataset, \n",
    "                 test_dataset, idx, epoch, global_weights) for idx in idxs_users])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train_mod(args, train_dataset, \n",
    "                        test_dataset, idx, epoch, global_weights=None):\n",
    "    # ...\n",
    "\n",
    "    # 客戶端訓練的代碼\n",
    "    local_weights, local_loss = client_train(args, train_dataset, \n",
    "                        test_dataset, idx, epoch, global_weights)\n",
    "\n",
    "    # 返回本地權重和損失\n",
    "    return local_weights, local_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 跑多個round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Global Training Round : 1 |\n",
      "\n",
      " process PID process PID  268233268232   running running\n",
      "\n",
      "load from  load from /mnt/Internal/FedASR/weitung/HuggingFace/Pretrain/saves/data2vec-audio-large-960h_new1_recall/final/ \n",
      "/mnt/Internal/FedASR/weitung/HuggingFace/Pretrain/saves/data2vec-audio-large-960h_new1_recall/final/ process PID\n",
      " 268233 enter critical section\n",
      "lambda =  tensor(0.5000)\n",
      "Current stage: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [07:52<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_237736/2004921703.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     final_result = pool.starmap(client_train, [(args, train_dataset, \n\u001b[0;32m---> 20\u001b[0;31m                         test_dataset, idx, epoch, global_weights) for idx in idxs_users])\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlocal_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Flower-speechbrain/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         '''\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m~/.conda/envs/Flower-speechbrain/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Flower-speechbrain/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Flower-speechbrain/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Flower-speechbrain/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss, test_wer = [], []\n",
    "val_acc_list, net_list = [], []\n",
    "cv_loss, cv_acc = [], []\n",
    "print_every = 2\n",
    "val_loss_pre, counter = 0, 0\n",
    "global_weights = None                                                           # initial global_weights\n",
    "# 創建進程間共享的 Queue 對象\n",
    "import multiprocessing as mp\n",
    "# manager = mp.Manager()\n",
    "# result_queue = manager.Queue()\n",
    "for epoch in tqdm(range(args.epochs)):                                          # train for given global rounds\n",
    "    #local_weights, local_losses = [], []                                        # weights and losses of training clients of this round\n",
    "    print(f'\\n | Global Training Round : {epoch+1} |\\n')                        # print current round\n",
    "\n",
    "    m = max(int(args.frac * args.num_users), 1)                                 # num of clients to train, min:1\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)      # select by client_id\n",
    "\n",
    "    pool = Pool(m)\n",
    "    final_result = pool.starmap(client_train, [(args, train_dataset, \n",
    "                        test_dataset, idx, epoch, global_weights) for idx in idxs_users])\n",
    "\n",
    "    local_weights = []\n",
    "    local_losses = []\n",
    "    # while not result_queue.empty():\n",
    "    #     w, loss = result_queue.get()\n",
    "    #     local_weights.append(w)\n",
    "    #     local_losses.append(loss)\n",
    "    # 舊的\n",
    "    for idx in range(len(final_result)):\n",
    "        w, loss = final_result[idx]\n",
    "        local_weights.append(w)\n",
    "        local_losses.append(loss)\n",
    "\n",
    "    print(\"local weights: \", local_weights)\n",
    "    # get global weights by averaging local weights\n",
    "    global_weights = average_weights(local_weights)\n",
    "    print(\"global wegiths: \", global_weights)\n",
    "\n",
    "    # update global weights\n",
    "    #global_model.load_state_dict(global_weights)\n",
    "\n",
    "    loss_avg = sum(local_losses) / len(local_losses)                # average losses from participated client\n",
    "    train_loss.append(loss_avg)                                     # save loss for this round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(final_result)):\n",
    "    w, loss = final_result[idx]\n",
    "    local_weights.append(w)\n",
    "    local_losses.append(loss)\n",
    "\n",
    "print(\"local weights: \", local_weights)\n",
    "# get global weights by averaging local weights\n",
    "global_weights = average_weights(local_weights)\n",
    "print(\"global wegiths: \", global_weights)\n",
    "\n",
    "# update global weights\n",
    "#global_model.load_state_dict(global_weights)\n",
    "\n",
    "loss_avg = sum(local_losses) / len(local_losses)                # average losses from participated client\n",
    "train_loss.append(loss_avg)                                     # save loss for this round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以下其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "train_loss, test_wer = [], []\n",
    "val_acc_list, net_list = [], []\n",
    "cv_loss, cv_acc = [], []\n",
    "print_every = 2\n",
    "val_loss_pre, counter = 0, 0\n",
    "global_weights = None    \n",
    "for epoch in range(2):\n",
    "    #for epoch in tqdm(range(args.epochs)):                                          # train for given global rounds\n",
    "    #local_weights, local_losses = [], []                                        # weights and losses of training clients of this round\n",
    "    print(f'\\n | Global Training Round : {epoch+1} |\\n')                        # print current round\n",
    "\n",
    "    m = max(int(args.frac * args.num_users), 1)                                 # num of clients to train, min:1\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)      # select by client_id\n",
    "\n",
    "    manager = multiprocessing.Manager()\n",
    "    return_dict = manager.dict()\n",
    "    jobs = []\n",
    "    #pipe_list = []\n",
    "    for idx in idxs_users:                                                      # for each training client\n",
    "\n",
    "        print(\"start of client #\", idx)\n",
    "        #recv_end, send_end = multiprocessing.Pipe(False)\n",
    "        p = multiprocessing.Process(target=client_train, args=(return_dict,\n",
    "                args, train_dataset, logger, test_dataset, idx, epoch, global_weights))\n",
    "\n",
    "        #p = multiprocessing.Process(target=client_get_weight, args=(return_dict, args, idx, epoch))\n",
    "        jobs.append(p)\n",
    "        #pipe_list.append(recv_end)\n",
    "        p.start()\n",
    "\n",
    "        #local_weights.append(copy.deepcopy(w))                      # save weight for this client\n",
    "        #local_losses.append(copy.deepcopy(loss))                    # save loss for this client\n",
    "    for proc in jobs:\n",
    "        proc.join()\n",
    "        #proc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(return_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "for idx in idxs_users:                                                      # for each training client\n",
    "    # get model weights from saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_weights = []\n",
    "local_losses = []\n",
    "for key in return_dict.keys():\n",
    "    w, loss = return_dict[key]\n",
    "    local_weights.append(w)\n",
    "    local_losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_weights = average_weights(local_weights)\n",
    "global_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model == 'data2vec':\n",
    "    mask_time_prob = 0                                                          # change config to avoid training stopping\n",
    "    config = Data2VecAudioConfig.from_pretrained(args.pretrain_name, mask_time_prob=mask_time_prob)\n",
    "    model = Data2VecAudioForCTC.from_pretrained(args.model_in_path, config=config, args=args)\n",
    "                                                                                # load/initialize global model\n",
    "    model.config.ctc_zero_infinity = True                                       # to avoid inf values\n",
    "\n",
    "    global_model = copy.deepcopy(model.arbitrator)                              # only has global toggling network\n",
    "    if global_weights != None:                                                  # if given global_weights\n",
    "        global_model.load_state_dict(global_weights)                            # load it\n",
    "    #else:\n",
    "    #    # copy weights\n",
    "    #    global_weights = copy.deepcopy(global_model.state_dict())                       # save global weight\n",
    "    processor = Wav2Vec2Processor.from_pretrained(args.pretrain_name)\n",
    "    data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "else:\n",
    "    exit('Error: unrecognized model')\n",
    "\n",
    "# Set the model to train and send it to device.\n",
    "global_model.to(device)\n",
    "global_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = global_model.state_dict()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "w_ret = OrderedDict()\n",
    "w_ret['weight'] = w['weight'].numpy()\n",
    "w_ret['bias'] = w['bias'].numpy()\n",
    "print(w_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w.cpu())\n",
    "#copy.deepcopy(w.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = multiprocessing.Manager()\n",
    "return_dict = manager.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict[2] = [global_model.state_dict(), 0.88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下尚未確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get global weights by averaging local weights\n",
    "global_weights = average_weights(local_weights)\n",
    "global_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update global weights\n",
    "global_model.load_state_dict(global_weights)\n",
    "\n",
    "loss_avg = sum(local_losses) / len(local_losses)                # average losses from participated client\n",
    "train_loss.append(loss_avg)     \n",
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_wer = []\n",
    "global_model.eval()\n",
    "for c in range(args.num_users):                                 # for ALL users\n",
    "    local_model = ASRLocalUpdate(args=args, dataset=train_dataset, logger=logger,\n",
    "                        data_collator=data_collator, global_test_dataset=test_dataset, \n",
    "                        processor=processor)\n",
    "                                                                # initial dataset of current client\n",
    "    wer = local_model.inference(global_arbitrator=global_model)       # get acc. & total loss on clients' test set\n",
    "    list_wer.append(wer)                                        # save acc.\n",
    "    #list_loss.append(loss)                                      # save loss\n",
    "train_accuracy.append(sum(list_wer)/len(list_wer))              # acc average over all clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下尚未確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# print global training loss after every 'i' rounds\n",
    "if (1+1) % print_every == 0:\n",
    "    print(f' \\nAvg Training Stats after {1+1} global rounds:')\n",
    "    print(f'Training Loss : {np.mean(np.array(train_loss))}')\n",
    "    print('Train Accuracy: {:.2f}% \\n'.format(100*train_accuracy[-1])) # on testing set of clients though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.training_args import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "import json\n",
    "\n",
    "LOG_DIR = './'#log/'\n",
    "from datasets import load_metric\n",
    "wer_metric = load_metric(\"wer\")\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}\n",
    "\n",
    "class CustomTrainer(Trainer):    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "            \"\"\"\n",
    "            How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
    "            Subclass and override for custom behavior.\n",
    "            \"\"\"\n",
    "            #dementia_labels = inputs.pop(\"dementia_labels\") # pop 出來就會不見?\n",
    "            \n",
    "            if self.label_smoother is not None and \"labels\" in inputs:\n",
    "                labels = inputs.pop(\"labels\")\n",
    "            else:\n",
    "                labels = None\n",
    "            \n",
    "            outputs = model(**inputs)\n",
    "            # Save past state if it exists\n",
    "            # TODO: this needs to be fixed and made cleaner later.\n",
    "            if self.args.past_index >= 0:\n",
    "                self._past = outputs[self.args.past_index]\n",
    "\n",
    "            if labels is not None:\n",
    "                loss = self.label_smoother(outputs, labels)\n",
    "            else:\n",
    "                # We don't use .loss here since the model may return tuples instead of ModelOutput.\n",
    "                loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
    "\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "    def log(self, logs: Dict[str, float]) -> None:\n",
    "        \"\"\"\n",
    "        Log `logs` on the various objects watching training.\n",
    "        Subclass and override this method to inject custom behavior.\n",
    "        Args:\n",
    "            logs (`Dict[str, float]`):\n",
    "                The values to log.\n",
    "        \"\"\"\n",
    "        if self.state.epoch is not None:\n",
    "            logs[\"epoch\"] = round(self.state.epoch, 2)\n",
    "\n",
    "        output = {**logs, **{\"step\": self.state.global_step}}\n",
    "        self.state.log_history.append(output)\n",
    "        \n",
    "        # write to txt file\n",
    "        file_object = open(LOG_DIR + args.log_path, 'a')\n",
    "        # Append at the end of file\n",
    "        file_object.write(json.dumps(output) + '\\n')\n",
    "        # Close the file\n",
    "        file_object.close()\n",
    "\n",
    "        self.control = self.callback_handler.on_log(self.args, self.state, self.control, logs)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=args.model_out_path + \"just_for_testing\",\n",
    "    group_by_length=True,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=2,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True, \n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    logging_steps=500,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.005,\n",
    "    warmup_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    log_level='debug',\n",
    "    logging_strategy=\"steps\",\n",
    "    #adafactor=True,            # default:false. Whether or not to use transformers.Adafactor optimizer instead of transformers.AdamW\n",
    "    #fp16_full_eval=True,      # to save memory\n",
    "    #max_grad_norm=0.5\n",
    ")\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.arbitrator.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.state.log_history[-1][\"train_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(args.epochs)):\n",
    "    local_weights, local_losses = [], []\n",
    "    print(f'\\n | Global Training Round : {epoch+1} |\\n') # epoch = round\n",
    "\n",
    "    global_model.train()\n",
    "    m = max(int(args.frac * args.num_users), 1) # 取部分client來train，至少一個client\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False) # 選client_id\n",
    "\n",
    "    for idx in idxs_users: # 每一位選上的client\n",
    "        # 做training?\n",
    "        local_model = LocalUpdate(args=args, dataset=train_dataset,\n",
    "                                    idxs=user_groups[idx], logger=logger)\n",
    "        # 得到這次的weights + loss\n",
    "        w, loss = local_model.update_weights(\n",
    "            model=copy.deepcopy(global_model), global_round=epoch)\n",
    "        local_weights.append(copy.deepcopy(w))\n",
    "        local_losses.append(copy.deepcopy(loss))\n",
    "\n",
    "    # compute global weights\n",
    "    global_weights = average_weights(local_weights)\n",
    "\n",
    "    # update global weights\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    loss_avg = sum(local_losses) / len(local_losses)\n",
    "    train_loss.append(loss_avg) # loss average over all clients\n",
    "\n",
    "    # Calculate avg training accuracy over all users at every epoch\n",
    "    list_acc, list_loss = [], []\n",
    "    global_model.eval()\n",
    "    for c in range(args.num_users): # 所有clients\n",
    "        # 做training? 應為update weight\n",
    "        local_model = LocalUpdate(args=args, dataset=train_dataset,\n",
    "                                    idxs=user_groups[idx], logger=logger)\n",
    "        # 用global model去測試，得到acc & loss\n",
    "        acc, loss = local_model.inference(model=global_model)\n",
    "        list_acc.append(acc)\n",
    "        list_loss.append(loss)\n",
    "    train_accuracy.append(sum(list_acc)/len(list_acc)) # acc_avg\n",
    "\n",
    "    # print global training loss after every 'i' rounds\n",
    "    if (epoch+1) % print_every == 0:\n",
    "        print(f' \\nAvg Training Stats after {epoch+1} global rounds:')\n",
    "        print(f'Training Loss : {np.mean(np.array(train_loss))}')\n",
    "        print('Train Accuracy: {:.2f}% \\n'.format(100*train_accuracy[-1]))\n",
    "\n",
    "# Test inference after completion of training\n",
    "test_acc, test_loss = test_inference(args, global_model, test_dataset)\n",
    "\n",
    "print(f' \\n Results after {args.epochs} global rounds of training:')\n",
    "print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100*train_accuracy[-1]))\n",
    "print(\"|---- Test Accuracy: {:.2f}%\".format(100*test_acc))\n",
    "\n",
    "# Saving the objects train_loss and train_accuracy:\n",
    "file_name = '../save/objects/{}_{}_{}_C[{}]_iid[{}]_E[{}]_B[{}].pkl'.\\\n",
    "    format(args.dataset, args.model, args.epochs, args.frac, args.iid,\n",
    "            args.local_ep, args.local_bs)\n",
    "\n",
    "# save 失敗\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump([train_loss, train_accuracy], f)\n",
    "\n",
    "print('\\n Total Run Time: {0:0.4f}'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
