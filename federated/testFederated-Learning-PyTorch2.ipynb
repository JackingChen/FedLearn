{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import argparse\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from options import args_parser\n",
    "from update import LocalUpdate, test_inference, ASRLocalUpdate\n",
    "from models import MLP, CNNMnist, CNNFashion_Mnist, CNNCifar, Data2VecAudioForCTC, DataCollatorCTCWithPadding\n",
    "from utils import get_dataset, average_weights, exp_details\n",
    "\n",
    "from transformers import Data2VecAudioConfig, Wav2Vec2Processor\n",
    "from multiprocessing import Pool\n",
    "from collections import OrderedDict\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# federated arguments (Notation for the arguments followed from paper)\n",
    "parser.add_argument('--epochs', type=int, default=2,\n",
    "                    help=\"number of rounds of training\")\n",
    "parser.add_argument('--num_users', type=int, default=2,\n",
    "                    help=\"number of users: K\")\n",
    "parser.add_argument('--frac', type=float, default=1.0,\n",
    "                    help='the fraction of clients: C')\n",
    "parser.add_argument('--local_ep', type=int, default=1,\n",
    "                    help=\"the number of local epochs: E\")\n",
    "\n",
    "parser.add_argument('--model', type=str, default='data2vec', help='model name')\n",
    "\n",
    "\n",
    "# other arguments\n",
    "parser.add_argument('--dataset', type=str, default='adress', help=\"name \\\n",
    "                    of dataset\") #cifar\n",
    "#parser.add_argument('--num_classes', type=int, default=10, help=\"number \\\n",
    "#                    of classes\")\n",
    "parser.add_argument('--gpu', default=1, help=\"To use cuda, set \\\n",
    "                    to a specific GPU ID. Default set to use CPU.\")\n",
    "\n",
    "# additional arguments\n",
    "parser.add_argument('--pretrain_name', type=str, default='facebook/data2vec-audio-large-960h', help=\"str used to load pretrain model\")\n",
    "parser.add_argument('-lam', '--LAMBDA', type=float, default=0.5, help=\"Lambda for GRL\")\n",
    "parser.add_argument('-st', '--STAGE', type=int, default=2, help=\"Current training stage\")\n",
    "parser.add_argument('-GRL', '--GRL', action='store_true', default=False, help=\"True: GRL\")\n",
    "parser.add_argument('-model_in', '--model_in_path', type=str, default=\"/mnt/Internal/FedASR/weitung/HuggingFace/Pretrain/saves/data2vec-audio-large-960h_new1_recall/final/\", help=\"Where the model is saved\")\n",
    "parser.add_argument('-model_out', '--model_out_path', type=str, default=\"./save/data2vec-audio-large-960h_new2_recall_FL\", help=\"Where to save the model\")\n",
    "parser.add_argument('-log', '--log_path', type=str, default=\"data2vec-audio-large-960h_new2_recall_FL.txt\", help=\"name for the txt file\")\n",
    "# 2023/01/08: loss type\n",
    "parser.add_argument('-ad_loss', '--AD_loss', type=str, default=\"recall\", help=\"loss to use for AD classifier\")\n",
    "# 2023/01/18: ckpt\n",
    "parser.add_argument('-ckpt', '--checkpoint', type=str, default=None, help=\"path to checkpoint\")\n",
    "# 2023/02/13: TOGGLE_RATIO\n",
    "parser.add_argument('-toggle_rt', '--TOGGLE_RATIO', type=float, default=0, help=\"To toggle more or less\")\n",
    "# 2023/02/15: GS_TAU, loss weight\n",
    "parser.add_argument('-gs_tau', '--GS_TAU', type=float, default=1, help=\"Tau for gumbel_softmax\")\n",
    "parser.add_argument('-w_loss', '--W_LOSS', type=float, default=None, nargs='+', help=\"weight for HC and AD\")\n",
    "\n",
    "args = parser.parse_args(args=[]) # for jupyter notebook\n",
    "\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\" # 或者其他你想要使用的 GPU 編號\n",
    "lock = mp.Lock()\n",
    "logger = SummaryWriter('../logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def client_train_old(args, train_dataset, logger,\n",
    "                 test_dataset, idx, epoch, global_weights=None):                    # train function for each client\n",
    "    print(\" process PID\", os.getpid(), \" running\")\n",
    "    \n",
    "    # BUILD MODEL for every process\n",
    "    if args.model == 'data2vec':\n",
    "        mask_time_prob = 0                                                          # change config to avoid training stopping\n",
    "        config = Data2VecAudioConfig.from_pretrained(args.pretrain_name, mask_time_prob=mask_time_prob)\n",
    "        print(\"load from \", args.model_in_path)\n",
    "        lock.acquire()\n",
    "        # print(\" process PID\", os.getpid(),\"enter critical section\")\n",
    "        # model = Data2VecAudioForCTC.from_pretrained(args.model_in_path, config=config, args=args)\n",
    "        # lock.release()\n",
    "        # print(\" process PID\", os.getpid(),\"exit critical section\")\n",
    "        try:\n",
    "            # 在這裡執行 critical section 的程式碼\n",
    "            print(\" process PID\", os.getpid(),\"enter critical section\")\n",
    "            model = Data2VecAudioForCTC.from_pretrained(args.model_in_path, config=config, args=args)\n",
    "            pass\n",
    "        finally:\n",
    "            # 在離開 critical section 後釋放鎖\n",
    "            lock.release()\n",
    "            print(\" process PID\", os.getpid(),\"exit critical section\")\n",
    "        print(\"model loaded\")                                                       # load/initialize global model\n",
    "        model.config.ctc_zero_infinity = True                                       # to avoid inf values\n",
    "\n",
    "        global_model = copy.deepcopy(model.arbitrator)                              # only has global toggling network\n",
    "        if global_weights != None:                                                  # if given global_weights\n",
    "            global_model.load_state_dict(global_weights)                            # load it\n",
    "        #else:\n",
    "        #    # copy weights\n",
    "        #    global_weights = copy.deepcopy(global_model.state_dict())                       # save global weight\n",
    "        processor = Wav2Vec2Processor.from_pretrained(args.pretrain_name)\n",
    "        data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "    else:\n",
    "        exit('Error: unrecognized model')\n",
    "\n",
    "    # Set the model to train and send it to device.\n",
    "    device = 'cuda' if args.gpu else 'cpu'\n",
    "    global_model.to(device)\n",
    "    global_model.train()\n",
    "    #print(global_model)\n",
    "\n",
    "    ####################\n",
    "    # 'use client_id generate sub-dataset' to be done\n",
    "    ####################\n",
    "    #print(\"call ASRLocalUpdate\")\n",
    "    local_model = ASRLocalUpdate(args=args, dataset=train_dataset, logger=logger,\n",
    "                        data_collator=data_collator, global_test_dataset=test_dataset, \n",
    "                        processor=processor, client_id=idx)\n",
    "                                                                                    # initial dataset of current client\n",
    "    ####################\n",
    "    # 'use client_id load local model' to be done\n",
    "    # 'save model in final round' to be done\n",
    "    ####################\n",
    "    #print(\"perform update_weight\")\n",
    "    w, loss = local_model.update_weights(\n",
    "        global_arbitrator=copy.deepcopy(global_model), global_round=epoch)          # from global model to train\n",
    "    \n",
    "    #send_end.send([w, loss])                                                        # save model weights and average round loss\n",
    "    #return_dict[str(idx)] = [w, loss]\n",
    "    print(\"PID {} Getting \".format(os.getpid()), \"Done\")\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def client_train_old2(args, train_dataset, logger,\n",
    "                 test_dataset, idx, epoch, global_weights=None, result_queue=None):                    # train function for each client\n",
    "    print(\" process PID\", os.getpid(), \" running\")\n",
    "    \n",
    "    # BUILD MODEL for every process\n",
    "    if args.model == 'data2vec':\n",
    "        mask_time_prob = 0                                                          # change config to avoid training stopping\n",
    "        config = Data2VecAudioConfig.from_pretrained(args.pretrain_name, mask_time_prob=mask_time_prob)\n",
    "        print(\"load from \", args.model_in_path)\n",
    "        lock.acquire()\n",
    "        # print(\" process PID\", os.getpid(),\"enter critical section\")\n",
    "        # model = Data2VecAudioForCTC.from_pretrained(args.model_in_path, config=config, args=args)\n",
    "        # lock.release()\n",
    "        # print(\" process PID\", os.getpid(),\"exit critical section\")\n",
    "        try:\n",
    "            # 在這裡執行 critical section 的程式碼\n",
    "            print(\" process PID\", os.getpid(),\"enter critical section\")\n",
    "            model = Data2VecAudioForCTC.from_pretrained(args.model_in_path, config=config, args=args)\n",
    "            pass\n",
    "        finally:\n",
    "            # 在離開 critical section 後釋放鎖\n",
    "            lock.release()\n",
    "            print(\" process PID\", os.getpid(),\"exit critical section\")\n",
    "        print(\"model loaded\")                                                       # load/initialize global model\n",
    "        model.config.ctc_zero_infinity = True                                       # to avoid inf values\n",
    "\n",
    "        global_model = copy.deepcopy(model.arbitrator)                              # only has global toggling network\n",
    "        if global_weights != None:                                                  # if given global_weights\n",
    "            global_model.load_state_dict(global_weights)                            # load it\n",
    "        #else:\n",
    "        #    # copy weights\n",
    "        #    global_weights = copy.deepcopy(global_model.state_dict())                       # save global weight\n",
    "        processor = Wav2Vec2Processor.from_pretrained(args.pretrain_name)\n",
    "        data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "    else:\n",
    "        exit('Error: unrecognized model')\n",
    "\n",
    "    # Set the model to train and send it to device.\n",
    "    device = 'cuda' if args.gpu else 'cpu'\n",
    "    global_model.to(device)\n",
    "    global_model.train()\n",
    "    #print(global_model)\n",
    "\n",
    "    ####################\n",
    "    # 'use client_id generate sub-dataset' to be done\n",
    "    ####################\n",
    "    #print(\"call ASRLocalUpdate\")\n",
    "    local_model = ASRLocalUpdate(args=args, dataset=train_dataset, logger=logger,\n",
    "                        data_collator=data_collator, global_test_dataset=test_dataset, \n",
    "                        processor=processor, client_id=idx)\n",
    "                                                                                    # initial dataset of current client\n",
    "    ####################\n",
    "    # 'use client_id load local model' to be done\n",
    "    # 'save model in final round' to be done\n",
    "    ####################\n",
    "    #print(\"perform update_weight\")\n",
    "    w, loss = local_model.update_weights(\n",
    "        global_arbitrator=copy.deepcopy(global_model), global_round=epoch)          # from global model to train\n",
    "    \n",
    "    # 將進程的結果存放在 result_queue 中\n",
    "    if result_queue is not None:\n",
    "        result_queue.put((w, loss))\n",
    "    #send_end.send([w, loss])                                                        # save model weights and average round loss\n",
    "    #return_dict[str(idx)] = [w, loss]\n",
    "    print(\"PID {} Getting \".format(os.getpid()), \"Done\")\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train(args, train_dataset, logger,\n",
    "                 test_dataset, idx, epoch, global_weights=None, result_queue=None):                    \n",
    "    print(\"process PID\", os.getpid(), \"running\")\n",
    "    # create lock\n",
    "    lock = mp.Lock()\n",
    "    # BUILD MODEL for every process\n",
    "    if args.model == 'data2vec':\n",
    "        mask_time_prob = 0                                                          \n",
    "        config = Data2VecAudioConfig.from_pretrained(args.pretrain_name, mask_time_prob=mask_time_prob)\n",
    "        print(\"load from \", args.model_in_path)\n",
    "        with lock:\n",
    "            model = Data2VecAudioForCTC.from_pretrained(args.model_in_path, config=config, args=args)\n",
    "        print(\"model loaded\")                                                       \n",
    "        model.config.ctc_zero_infinity = True                                       \n",
    "\n",
    "        global_model = copy.deepcopy(model.arbitrator)                              \n",
    "        if global_weights != None:                                                  \n",
    "            global_model.load_state_dict(global_weights)                            \n",
    "        processor = Wav2Vec2Processor.from_pretrained(args.pretrain_name)\n",
    "        data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "    else:\n",
    "        exit('Error: unrecognized model')\n",
    "\n",
    "    # Set the model to train and send it to device.\n",
    "    device = 'cuda' if args.gpu else 'cpu'\n",
    "    global_model.to(device)\n",
    "    global_model.train()\n",
    "\n",
    "    # generate sub-dataset\n",
    "    local_dataset = generate_local_dataset(train_dataset, idx, args.num_users)\n",
    "    local_model = ASRLocalUpdate(args=args, dataset=local_dataset, logger=logger,\n",
    "                        data_collator=data_collator, global_test_dataset=test_dataset, \n",
    "                        processor=processor, client_id=idx)\n",
    "\n",
    "    try:\n",
    "        w, loss = local_model.update_weights(\n",
    "            global_arbitrator=copy.deepcopy(global_model), global_round=epoch)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while running local_model.update_weights(): {str(e)}\")\n",
    "    else:\n",
    "        # save model weights and average round loss\n",
    "        if result_queue is not None:\n",
    "            result_queue.put((w, loss))\n",
    "        print(\"process PID {} done\".format(os.getpid()))\n",
    "    return w, loss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拆解上面那個client train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train_toy(args, train_dataset, logger,\n",
    "                 test_dataset, idx, epoch, global_weights=None, result_queue=None):                    \n",
    "    print(\"process PID\", os.getpid(), \"running\")\n",
    "    sys.stdout.flush()\n",
    "    # create lock\n",
    "    lock = mp.Lock()\n",
    "    # BUILD MODEL for every process\n",
    "    if args.model == 'data2vec':\n",
    "        mask_time_prob = 0                                                          \n",
    "        config = Data2VecAudioConfig.from_pretrained(args.pretrain_name, mask_time_prob=mask_time_prob)\n",
    "        print(\"load from \", args.model_in_path)\n",
    "        with lock:\n",
    "            model = Data2VecAudioForCTC.from_pretrained(args.model_in_path, config=config, args=args)\n",
    "        print(\"model loaded\")                                                       \n",
    "        model.config.ctc_zero_infinity = True                                       \n",
    "\n",
    "        global_model = copy.deepcopy(model.arbitrator)                              \n",
    "        if global_weights != None:                                                  \n",
    "            global_model.load_state_dict(global_weights)                            \n",
    "        processor = Wav2Vec2Processor.from_pretrained(args.pretrain_name)\n",
    "        data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "    else:\n",
    "        exit('Error: unrecognized model')\n",
    "    \n",
    "    print(\"process PID {} done\".format(os.getpid()))\n",
    "    sys.stdout.flush()\n",
    "    return 1,2\n",
    "    # # Set the model to train and send it to device.\n",
    "    # device = 'cuda' if args.gpu else 'cpu'\n",
    "    # global_model.to(device)\n",
    "    # global_model.train()\n",
    "\n",
    "    # # generate sub-dataset\n",
    "    # local_dataset = generate_local_dataset(train_dataset, idx, args.num_users)\n",
    "    # local_model = ASRLocalUpdate(args=args, dataset=local_dataset, logger=logger,\n",
    "    #                     data_collator=data_collator, global_test_dataset=test_dataset, \n",
    "    #                     processor=processor, client_id=idx)\n",
    "\n",
    "    # try:\n",
    "    #     w, loss = local_model.update_weights(\n",
    "    #         global_arbitrator=copy.deepcopy(global_model), global_round=epoch)\n",
    "    # except Exception as e:\n",
    "    #     print(f\"An error occurred while running local_model.update_weights(): {str(e)}\")\n",
    "    # else:\n",
    "    #     # save model weights and average round loss\n",
    "    #     if result_queue is not None:\n",
    "    #         result_queue.put((w, loss))\n",
    "    #     print(\"process PID {} done\".format(os.getpid()))\n",
    "    # return w, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/FedASR/dacs/federated/dataset/train/cache-b6f4c0d2143105d5_*_of_00010.arrow\n",
      "Loading cached processed dataset at /home/FedASR/dacs/federated/dataset/test/cache-f07dc6d726972452_*_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from local...\n",
      "Load data from local...\n",
      "\n",
      " | Global Training Round : 1 |\n",
      "\n",
      "Training clients: [1 0]\n",
      "Final result: <multiprocessing.pool.MapResult object at 0x7fd8b543c590>\n",
      "Local weights: []\n",
      "\n",
      " | Global Training Round : 2 |\n",
      "\n",
      "Training clients: [0 1]\n",
      "Final result: <multiprocessing.pool.MapResult object at 0x7fd8b5446e90>\n",
      "Local weights: []\n"
     ]
    }
   ],
   "source": [
    "train_loss, test_wer = [], []\n",
    "val_acc_list, net_list = [], []\n",
    "cv_loss, cv_acc = [], []\n",
    "print_every = 2\n",
    "val_loss_pre, counter = 0, 0\n",
    "global_weights = None                                                           # initial global_weights\n",
    "# 創建進程間共享的 Queue 對象\n",
    "manager = mp.Manager()\n",
    "result_queue = manager.Queue()\n",
    "\n",
    "train_dataset, test_dataset, user_groups = get_dataset(args)\n",
    "for epoch in range(args.epochs):                                          # train for given global rounds\n",
    "    #local_weights, local_losses = [], []                                        # weights and losses of training clients of this round\n",
    "    print(f'\\n | Global Training Round : {epoch+1} |\\n')                        # print current round\n",
    "\n",
    "    m = max(int(args.frac * args.num_users), 1)                                 # num of clients to train, min:1\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)      # select by client_id\n",
    "\n",
    "    pool = Pool(m)\n",
    "    # final_result = pool.starmap(client_train, [(args, train_dataset, logger,\n",
    "    #                     test_dataset, idx, epoch, global_weights) for idx in idxs_users])\n",
    "    print(\"Training clients:\", idxs_users)\n",
    "    # final_result = pool.starmap_async(\n",
    "    #     client_train, [(args, train_dataset, logger,\n",
    "    #                     test_dataset, idx, epoch, global_weights, result_queue)\n",
    "    #                    for idx in idxs_users])\n",
    "    try:\n",
    "        final_result = pool.starmap_async(\n",
    "            client_train, [(args, train_dataset, logger,\n",
    "                            test_dataset, idx, epoch, global_weights, result_queue)\n",
    "                        for idx in idxs_users])\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while running local_model.update_weights(): {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    local_weights = []\n",
    "    local_losses = []\n",
    "    while not result_queue.empty():\n",
    "        w, loss = result_queue.get()\n",
    "        local_weights.append(w)\n",
    "        local_losses.append(loss)\n",
    "    # 舊的\n",
    "    # for idx in range(len(final_result)):\n",
    "    #     w, loss = final_result[idx]\n",
    "    #     local_weights.append(w)\n",
    "    #     local_losses.append(loss)\n",
    "\n",
    "    print(\"Final result:\", final_result)\n",
    "    print(\"Local weights:\", local_weights)\n",
    "\n",
    "\n",
    "    # 這邊等修好了再解除comment\n",
    "    # print(\"local weights: \", local_weights)\n",
    "    # # get global weights by averaging local weights\n",
    "    # global_weights = average_weights(local_weights)\n",
    "    # print(\"global wegiths: \", global_weights)\n",
    "\n",
    "    # # update global weights\n",
    "    # #global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # loss_avg = sum(local_losses) / len(local_losses)                # average losses from participated client\n",
    "    # train_loss.append(loss_avg)                                     # save loss for this round"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拆解上面那個coding block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 替換成pool.map寫法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/FedASR/dacs/federated/dataset/train/cache-b6f4c0d2143105d5_*_of_00010.arrow\n",
      "Loading cached processed dataset at /home/FedASR/dacs/federated/dataset/test/cache-f07dc6d726972452_*_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from local...\n",
      "Load data from local...\n",
      "\n",
      " | Global Training Round : 1 |\n",
      "\n",
      "stepping in client_train_map\n",
      "An error occurred while running local_model.update_weights(): Queue objects should only be shared between processes through inheritance\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'MapResult' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_613943/3204631907.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mlocal_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mlocal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinal_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mlocal_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mlocal_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'MapResult' object is not iterable"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "train_loss, test_wer = [], []\n",
    "val_acc_list, net_list = [], []\n",
    "cv_loss, cv_acc = [], []\n",
    "print_every = 2\n",
    "val_loss_pre, counter = 0, 0\n",
    "global_weights = None                                                           # initial global_weights\n",
    "# 創建進程間共享的 Queue 對象\n",
    "# manager = mp.Manager()\n",
    "# result_queue = manager.Queue()\n",
    "\n",
    "train_dataset, test_dataset, user_groups = get_dataset(args)\n",
    "\n",
    "def client_train_map(args_train):                    \n",
    "    print(\"process PID\", os.getpid(), \"running\")\n",
    "    # args, train_dataset, logger, test_dataset, idx, epoch, global_weights, result_queue = args_train\n",
    "    args, train_dataset, logger, test_dataset, idx, epoch, global_weights = args_train\n",
    "    sys.stdout.flush()\n",
    "    # create lock\n",
    "    lock = mp.Lock()\n",
    "    # BUILD MODEL for every process\n",
    "    if args.model == 'data2vec':\n",
    "        mask_time_prob = 0                                                          \n",
    "        config = Data2VecAudioConfig.from_pretrained(args.pretrain_name, mask_time_prob=mask_time_prob)\n",
    "        print(\"load from \", args.model_in_path)\n",
    "        with lock:\n",
    "            model = Data2VecAudioForCTC.from_pretrained(args.model_in_path, config=config, args=args)\n",
    "        print(\"model loaded\")                                                       \n",
    "        model.config.ctc_zero_infinity = True                                       \n",
    "\n",
    "        global_model = copy.deepcopy(model.arbitrator)                              \n",
    "        if global_weights != None:                                                  \n",
    "            global_model.load_state_dict(global_weights)                            \n",
    "        processor = Wav2Vec2Processor.from_pretrained(args.pretrain_name)\n",
    "        data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "    else:\n",
    "        exit('Error: unrecognized model')\n",
    "    \n",
    "    print(\"process PID {} done\".format(os.getpid()))\n",
    "    sys.stdout.flush()\n",
    "    # result_queue.put((1, 2))\n",
    "    return 1,2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(args.epochs):                                          # train for given global rounds\n",
    "    print(f'\\n | Global Training Round : {epoch+1} |\\n')                        # print current round\n",
    "    m = max(int(args.frac * args.num_users), 1)                                 # num of clients to train, min:1\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)      # select by client_id\n",
    "    \n",
    "    \n",
    "    # pool = Pool(m)\n",
    "    # print(\"Training clients:\", idxs_users)\n",
    "    # try:\n",
    "    #     # final_result = pool.starmap_async(\n",
    "    #     #     client_train, [(args, train_dataset, logger,\n",
    "    #     #                     test_dataset, idx, epoch, global_weights, result_queue)\n",
    "    #     #                 for idx in idxs_users])\n",
    "    #     print(\"stepping in client_train_map\")\n",
    "    #     # final_result = pool.starmap_async(\n",
    "    #     #     client_train_toy, [(args, train_dataset, logger,\n",
    "    #     #                     test_dataset, idx, epoch, global_weights, result_queue)\n",
    "    #     #                 for idx in idxs_users])\n",
    "    #     final_result = pool.map(client_train_map, [(args, train_dataset, logger,\n",
    "    #                                     test_dataset, idx, epoch, global_weights, result_queue)\n",
    "    #                                   for idx in idxs_users])\n",
    "    #     # while not final_result.ready():\n",
    "    #     #     time.sleep(0.1)\n",
    "    #     # final_result_content = final_result.get()\n",
    "    #     # print(\"final_result_content: \",final_result_content)\n",
    "    # except Exception as e:\n",
    "    #     print(f\"An error occurred while running local_model.update_weights(): {str(e)}\")\n",
    "    # pool.close()\n",
    "    # pool.join()\n",
    "\n",
    "    # 換另一種call法\n",
    "    # with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    #     try:\n",
    "    #         print(\"stepping in client_train_map\")\n",
    "    #         # final_result = list(executor.map(client_train_map, [(args, train_dataset, logger,\n",
    "    #         #                                 test_dataset, idx, epoch, global_weights, result_queue)\n",
    "    #         #                               for idx in idxs_users]))\n",
    "    #         final_result = list(executor.map(client_train_map, [(args, train_dataset, logger,\n",
    "    #                                         test_dataset, idx, epoch, global_weights)  # removed result_queue\n",
    "    #                                       for idx in idxs_users]))\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"An error occurred while running local_model.update_weights(): {str(e)}\")\n",
    "    \n",
    "    # 換另2種call法\n",
    "    with mp.Pool(m) as pool:\n",
    "        try:\n",
    "            print(\"stepping in client_train_map\")\n",
    "            final_result = pool.map(client_train_map, [(args, train_dataset, logger,\n",
    "                                            test_dataset, idx, epoch, global_weights)\n",
    "                                          for idx in idxs_users])\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while running local_model.update_weights(): {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "    local_weights = []\n",
    "    local_losses = []\n",
    "    for w, loss in final_result:\n",
    "        local_weights.append(w)\n",
    "        local_losses.append(loss)\n",
    "    # while not result_queue.empty():\n",
    "    #     w, loss = result_queue.get()\n",
    "    #     local_weights.append(w)\n",
    "    #     local_losses.append(loss)\n",
    "    print(\"Final result:\", final_result)\n",
    "    print(\"Local weights:\", local_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flower-speechbrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
