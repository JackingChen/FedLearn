{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_from_disk\n",
    "import librosa\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Trainer, TrainingArguments\n",
    "from transformers import Data2VecAudioConfig, HubertConfig, SEWDConfig, UniSpeechSatConfig\n",
    "from transformers import Data2VecAudioForCTC, HubertForCTC, SEWDForCTC, UniSpeechSatForCTC\n",
    "from jiwer import wer\n",
    "import scipy.io\n",
    "# set up trainer\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"array\"]\n",
    "\n",
    "    # batched output is \"un-batched\" to ensure mapping is correct\n",
    "    batch[\"input_values\"] = processor(audio, sampling_rate=16000).input_values[0]\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"text\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    wer_metric = load_metric(\"wer\")\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}\n",
    "\n",
    "def map_to_result(batch):\n",
    "    with torch.no_grad():\n",
    "        input_values = torch.tensor(batch[\"input_values\"]).unsqueeze(0)\n",
    "        logits = new_model(input_values).logits\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    batch[\"pred_str\"] = new_processor.batch_decode(pred_ids)[0]\n",
    "    batch[\"text\"] = new_processor.decode(batch[\"labels\"], group_tokens=False)\n",
    "  \n",
    "    return batch\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('-model', '--model_path', type=str, default=\"./saves/wav2vec2-base-960h_GRL_0.5\", help=\"Where the model is saved\")\n",
    "parser.add_argument('-opt', '--optimizer', type=str, default=\"adamw_hf\", help=\"The optimizer to use: adamw_hf, adamw_torch, adamw_apex_fused, or adafactor\")\n",
    "parser.add_argument('-MGN', '--max_grad_norm', type=float, default=1.0, help=\"Maximum gradient norm (for gradient clipping)\")\n",
    "parser.add_argument('-model_type', '--model_type', type=str, default=\"data2vec\", help=\"Type of the model\")\n",
    "parser.add_argument('-sr', '--sampl_rate', type=float, default=16000, help=\"librosa read smping rate\")\n",
    "parser.add_argument('-lr', '--learning_rate', type=float, default=1e-4, help=\"Learning rate\")\n",
    "parser.add_argument('-RD', '--root_dir', default='/mnt/Internal/FedASR/Data/ADReSS-IS2020-data', help=\"Learning rate\")\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "def csv2dataset(audio_path = '{}/clips/'.format(args.root_dir),\n",
    "                csv_path = '{}/mid_csv/test.csv'.format(args.root_dir),\\\n",
    "                bookKeep = None):\n",
    "    stored = \"./dataset/\" + csv_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    if (os.path.exists(stored)):\n",
    "        #print(\"loaded\")\n",
    "        return load_from_disk(stored)\n",
    "        \n",
    "    data = pd.read_csv(csv_path)                                                # read desired csv\n",
    "    dataset = Dataset.from_pandas(data)                                     # turn into class dataset\n",
    "    \n",
    "    # initialize a dictionary\n",
    "    my_dict = {}\n",
    "    my_dict[\"path\"] = []                                                   # path to audio\n",
    "    my_dict[\"array\"] = []                                                  # waveform in array\n",
    "    my_dict[\"text\"] = []                                                   # ground truth transcript\n",
    "\n",
    "    i = 1\n",
    "    for file_path in dataset['path']:                                           # for all files\n",
    "        if dataset['sentence'][i-1] != None:                               # only the non-empty transcript\n",
    "            # sig, s = librosa.load('{0}/{1}'.format(audio_path,file_path), sr=args.sampl_rate, dtype='float32')  # read audio w/ 16k sr\n",
    "            s, sig = scipy.io.wavfile.read('{0}/{1}'.format(audio_path,file_path))\n",
    "            sig=librosa.util.normalize(sig)\n",
    "            my_dict[\"path\"].append(file_path)                                   # add path\n",
    "            my_dict[\"array\"].append(sig)                                   # add audio wave\n",
    "            my_dict[\"text\"].append(dataset['sentence'][i-1].upper())       # transcript to uppercase\n",
    "        print(i, end=\"\\r\")                                                 # print progress\n",
    "        i += 1\n",
    "    print(\"There're \", len(my_dict[\"path\"]), \" non-empty files.\")\n",
    "\n",
    "    result_dataset = Dataset.from_dict(my_dict)\n",
    "    if bookKeep:\n",
    "        bookKeep['data']=sig\n",
    "    return result_dataset\n",
    "\n",
    "#model_out_dir = args.model_path # where to save model\n",
    "model_type = args.model_type                # what type of the model\n",
    "lr = args.learning_rate                     # learning rate\n",
    "optim = args.optimizer                      # opt\n",
    "max_grad_norm = args.max_grad_norm          # max_grad_norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There're  1869  non-empty files.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1124438/3736857447.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# dev_data = csv2dataset(csv_path = \"{}/mid_csv/dev.csv\".format(args.root_dir))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# test_data = csv2dataset(csv_path = \"{}/mid_csv/test.csv\".format(args.root_dir))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbookKeep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "\n",
    "# load in train-dev-test\n",
    "bookKeep={}\n",
    "train_data = csv2dataset(csv_path = \"{}/mid_csv/train.csv\".format(args.root_dir))\n",
    "# dev_data = csv2dataset(csv_path = \"{}/mid_csv/dev.csv\".format(args.root_dir))\n",
    "# test_data = csv2dataset(csv_path = \"{}/mid_csv/test.csv\".format(args.root_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data['array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "librosa.load運行時間: 0.059068 秒\n",
      "[-6.1035156e-05 -9.1552734e-05 -9.1552734e-05 -6.1035156e-05\n",
      "  0.0000000e+00 -3.0517578e-05 -3.0517578e-05 -3.0517578e-05\n",
      " -6.1035156e-05 -9.1552734e-05 -1.2207031e-04 -1.2207031e-04\n",
      " -9.1552734e-05 -6.1035156e-05 -6.1035156e-05 -9.1552734e-05\n",
      " -9.1552734e-05 -9.1552734e-05 -9.1552734e-05 -6.1035156e-05\n",
      " -6.1035156e-05 -3.0517578e-05  0.0000000e+00 -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00  3.0517578e-05  6.1035156e-05\n",
      "  9.1552734e-05  9.1552734e-05  1.2207031e-04  1.2207031e-04\n",
      "  9.1552734e-05  6.1035156e-05  6.1035156e-05  6.1035156e-05\n",
      "  6.1035156e-05  6.1035156e-05  6.1035156e-05  6.1035156e-05\n",
      "  3.0517578e-05  3.0517578e-05  0.0000000e+00 -3.0517578e-05\n",
      " -3.0517578e-05 -6.1035156e-05 -6.1035156e-05 -9.1552734e-05\n",
      " -1.2207031e-04 -1.2207031e-04 -1.5258789e-04 -1.5258789e-04\n",
      " -1.2207031e-04 -9.1552734e-05 -1.2207031e-04 -9.1552734e-05\n",
      " -1.2207031e-04 -9.1552734e-05 -9.1552734e-05 -9.1552734e-05\n",
      " -6.1035156e-05  0.0000000e+00  3.0517578e-05  6.1035156e-05\n",
      "  6.1035156e-05  6.1035156e-05  6.1035156e-05  9.1552734e-05\n",
      "  6.1035156e-05  6.1035156e-05  9.1552734e-05  9.1552734e-05\n",
      "  3.0517578e-05  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  3.0517578e-05  3.0517578e-05  3.0517578e-05  3.0517578e-05\n",
      "  3.0517578e-05 -3.0517578e-05 -6.1035156e-05 -9.1552734e-05\n",
      " -6.1035156e-05  0.0000000e+00 -6.1035156e-05  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00 -3.0517578e-05  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00 -3.0517578e-05  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00 -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05  0.0000000e+00 -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05 -3.0517578e-05  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00 -3.0517578e-05  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05  0.0000000e+00 -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05  0.0000000e+00 -3.0517578e-05\n",
      " -6.1035156e-05  0.0000000e+00 -3.0517578e-05  0.0000000e+00\n",
      "  3.0517578e-05  0.0000000e+00  0.0000000e+00 -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05 -3.0517578e-05 -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00 -3.0517578e-05  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05 -3.0517578e-05  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05  0.0000000e+00 -3.0517578e-05\n",
      " -3.0517578e-05 -6.1035156e-05 -3.0517578e-05  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00 -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05  0.0000000e+00  0.0000000e+00\n",
      " -3.0517578e-05  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05  0.0000000e+00 -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00 -3.0517578e-05\n",
      "  0.0000000e+00 -6.1035156e-05 -3.0517578e-05 -3.0517578e-05\n",
      "  0.0000000e+00  3.0517578e-05 -3.0517578e-05  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05 -3.0517578e-05  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05 -6.1035156e-05  0.0000000e+00 -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05 -3.0517578e-05 -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      " -6.1035156e-05  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00 -3.0517578e-05  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05  0.0000000e+00 -3.0517578e-05\n",
      "  0.0000000e+00  1.2207031e-04  0.0000000e+00  3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05  0.0000000e+00 -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      "  0.0000000e+00 -6.1035156e-05 -9.1552734e-05 -9.1552734e-05\n",
      " -9.1552734e-05 -6.1035156e-05  3.0517578e-05  0.0000000e+00\n",
      "  6.1035156e-05  0.0000000e+00  0.0000000e+00  3.0517578e-05\n",
      "  3.0517578e-05  0.0000000e+00  3.0517578e-05  0.0000000e+00\n",
      " -3.0517578e-05  0.0000000e+00  3.0517578e-05  0.0000000e+00\n",
      "  0.0000000e+00 -6.1035156e-05 -6.1035156e-05 -9.1552734e-05\n",
      " -1.2207031e-04 -6.1035156e-05 -3.0517578e-05 -6.1035156e-05\n",
      " -3.0517578e-05  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  3.0517578e-05 -3.0517578e-05  0.0000000e+00 -3.0517578e-05\n",
      "  0.0000000e+00  9.1552734e-05  6.1035156e-05  3.0517578e-05\n",
      "  3.0517578e-05 -6.1035156e-05 -6.1035156e-05 -3.0517578e-05\n",
      " -6.1035156e-05 -3.0517578e-05 -3.0517578e-05 -6.1035156e-05\n",
      " -3.0517578e-05 -6.1035156e-05 -3.0517578e-05 -3.0517578e-05\n",
      "  0.0000000e+00 -9.1552734e-05  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  6.1035156e-05  3.0517578e-05  3.0517578e-05\n",
      "  3.0517578e-05  0.0000000e+00  3.0517578e-05  3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05 -3.0517578e-05 -9.1552734e-05\n",
      " -3.0517578e-05 -3.0517578e-05 -3.0517578e-05 -6.1035156e-05\n",
      " -6.1035156e-05 -9.1552734e-05 -6.1035156e-05 -3.0517578e-05\n",
      "  0.0000000e+00  6.1035156e-05  0.0000000e+00  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05  0.0000000e+00  3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05 -6.1035156e-05 -6.1035156e-05\n",
      " -9.1552734e-05 -9.1552734e-05 -3.0517578e-05  0.0000000e+00\n",
      " -3.0517578e-05 -3.0517578e-05 -3.0517578e-05 -3.0517578e-05\n",
      "  0.0000000e+00  3.0517578e-05  3.0517578e-05  3.0517578e-05\n",
      "  0.0000000e+00  3.0517578e-05  3.0517578e-05  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00 -6.1035156e-05 -6.1035156e-05\n",
      " -9.1552734e-05 -6.1035156e-05 -9.1552734e-05 -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00 -6.1035156e-05  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05  3.0517578e-05  6.1035156e-05\n",
      "  6.1035156e-05 -3.0517578e-05  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00 -3.0517578e-05\n",
      " -6.1035156e-05 -9.1552734e-05 -3.0517578e-05 -6.1035156e-05\n",
      " -9.1552734e-05 -6.1035156e-05 -3.0517578e-05 -3.0517578e-05\n",
      "  0.0000000e+00  3.0517578e-05 -3.0517578e-05  0.0000000e+00\n",
      " -6.1035156e-05  3.0517578e-05  6.1035156e-05  3.0517578e-05\n",
      "  6.1035156e-05  9.1552734e-05 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05 -6.1035156e-05 -3.0517578e-05 -3.0517578e-05\n",
      " -6.1035156e-05 -3.0517578e-05 -6.1035156e-05 -6.1035156e-05\n",
      "  3.0517578e-05 -9.1552734e-05 -6.1035156e-05 -3.0517578e-05\n",
      " -6.1035156e-05  0.0000000e+00  3.0517578e-05  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05  0.0000000e+00  6.1035156e-05\n",
      "  3.0517578e-05 -3.0517578e-05  0.0000000e+00 -6.1035156e-05\n",
      " -9.1552734e-05  0.0000000e+00  0.0000000e+00 -3.0517578e-05\n",
      "  0.0000000e+00 -9.1552734e-05 -9.1552734e-05 -9.1552734e-05\n",
      " -1.2207031e-04 -3.0517578e-05  3.0517578e-05 -3.0517578e-05\n",
      "  6.1035156e-05  6.1035156e-05  0.0000000e+00  3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05  0.0000000e+00 -3.0517578e-05\n",
      "  3.0517578e-05  6.1035156e-05  3.0517578e-05  0.0000000e+00\n",
      "  0.0000000e+00 -1.2207031e-04 -1.2207031e-04 -3.0517578e-05\n",
      " -9.1552734e-05 -6.1035156e-05  0.0000000e+00 -6.1035156e-05\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  6.1035156e-05\n",
      " -6.1035156e-05 -6.1035156e-05  3.0517578e-05  0.0000000e+00\n",
      "  3.0517578e-05  9.1552734e-05  6.1035156e-05  3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05 -3.0517578e-05 -6.1035156e-05\n",
      " -9.1552734e-05 -3.0517578e-05 -3.0517578e-05 -9.1552734e-05\n",
      "  3.0517578e-05  0.0000000e+00 -6.1035156e-05 -3.0517578e-05\n",
      " -6.1035156e-05 -9.1552734e-05  0.0000000e+00  0.0000000e+00\n",
      "  6.1035156e-05  9.1552734e-05  0.0000000e+00  6.1035156e-05\n",
      "  6.1035156e-05 -3.0517578e-05  0.0000000e+00 -3.0517578e-05\n",
      " -6.1035156e-05 -6.1035156e-05 -3.0517578e-05  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05 -6.1035156e-05 -6.1035156e-05\n",
      " -1.2207031e-04 -9.1552734e-05  0.0000000e+00 -3.0517578e-05\n",
      "  0.0000000e+00  3.0517578e-05  3.0517578e-05  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05  3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05  3.0517578e-05  3.0517578e-05  0.0000000e+00\n",
      "  6.1035156e-05 -3.0517578e-05 -6.1035156e-05 -9.1552734e-05\n",
      " -9.1552734e-05 -6.1035156e-05 -6.1035156e-05 -6.1035156e-05\n",
      "  0.0000000e+00 -3.0517578e-05  0.0000000e+00  0.0000000e+00\n",
      "  6.1035156e-05 -3.0517578e-05 -3.0517578e-05  0.0000000e+00\n",
      "  0.0000000e+00  3.0517578e-05  9.1552734e-05  6.1035156e-05\n",
      "  3.0517578e-05  0.0000000e+00 -3.0517578e-05 -3.0517578e-05\n",
      " -6.1035156e-05 -6.1035156e-05 -3.0517578e-05 -6.1035156e-05\n",
      " -6.1035156e-05 -3.0517578e-05  0.0000000e+00 -3.0517578e-05\n",
      " -3.0517578e-05 -6.1035156e-05 -3.0517578e-05 -3.0517578e-05\n",
      "  0.0000000e+00  6.1035156e-05  6.1035156e-05  3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05 -6.1035156e-05 -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05 -3.0517578e-05 -6.1035156e-05\n",
      " -6.1035156e-05 -9.1552734e-05 -6.1035156e-05 -3.0517578e-05\n",
      "  0.0000000e+00 -3.0517578e-05  0.0000000e+00  3.0517578e-05\n",
      "  0.0000000e+00  3.0517578e-05  6.1035156e-05  0.0000000e+00\n",
      "  0.0000000e+00 -3.0517578e-05  0.0000000e+00  3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00 -9.1552734e-05\n",
      " -9.1552734e-05 -3.0517578e-05 -6.1035156e-05 -6.1035156e-05\n",
      " -3.0517578e-05 -6.1035156e-05 -3.0517578e-05 -3.0517578e-05\n",
      "  0.0000000e+00  6.1035156e-05  0.0000000e+00 -3.0517578e-05\n",
      "  3.0517578e-05  0.0000000e+00  0.0000000e+00  6.1035156e-05\n",
      "  3.0517578e-05  0.0000000e+00  0.0000000e+00 -3.0517578e-05\n",
      " -3.0517578e-05 -3.0517578e-05 -6.1035156e-05 -3.0517578e-05\n",
      " -6.1035156e-05 -1.2207031e-04 -3.0517578e-05 -3.0517578e-05\n",
      " -6.1035156e-05  0.0000000e+00 -3.0517578e-05 -6.1035156e-05\n",
      "  3.0517578e-05  0.0000000e+00  6.1035156e-05  6.1035156e-05\n",
      "  0.0000000e+00  0.0000000e+00  6.1035156e-05 -3.0517578e-05\n",
      "  3.0517578e-05  3.0517578e-05 -3.0517578e-05 -3.0517578e-05\n",
      " -3.0517578e-05 -6.1035156e-05 -3.0517578e-05 -6.1035156e-05\n",
      " -9.1552734e-05 -3.0517578e-05 -9.1552734e-05 -6.1035156e-05\n",
      "  3.0517578e-05  0.0000000e+00  0.0000000e+00  3.0517578e-05\n",
      " -3.0517578e-05  0.0000000e+00  3.0517578e-05  3.0517578e-05\n",
      "  6.1035156e-05  3.0517578e-05 -3.0517578e-05  3.0517578e-05\n",
      "  0.0000000e+00 -6.1035156e-05  0.0000000e+00 -3.0517578e-05\n",
      " -9.1552734e-05 -6.1035156e-05 -6.1035156e-05 -6.1035156e-05\n",
      "  0.0000000e+00 -6.1035156e-05 -3.0517578e-05 -6.1035156e-05\n",
      " -6.1035156e-05  0.0000000e+00  6.1035156e-05  0.0000000e+00\n",
      "  3.0517578e-05  6.1035156e-05  0.0000000e+00  6.1035156e-05\n",
      "  3.0517578e-05  3.6621094e-04  3.0517578e-04  1.2207031e-04\n",
      "  0.0000000e+00  9.1552734e-05  0.0000000e+00 -6.1035156e-05\n",
      " -9.1552734e-05 -1.5258789e-04 -1.8310547e-04 -1.5258789e-04\n",
      " -1.8310547e-04 -1.2207031e-04 -1.2207031e-04 -1.5258789e-04\n",
      " -1.2207031e-04 -1.2207031e-04 -1.5258789e-04 -6.1035156e-05\n",
      " -3.0517578e-05 -1.2207031e-04 -1.8310547e-04 -1.5258789e-04\n",
      " -1.2207031e-04 -1.2207031e-04 -2.1362305e-04 -2.7465820e-04\n",
      " -2.4414062e-04 -3.9672852e-04 -4.5776367e-04 -3.3569336e-04\n",
      " -2.4414062e-04 -1.8310547e-04 -1.8310547e-04 -1.5258789e-04\n",
      "  3.0517578e-05  6.1035156e-05  0.0000000e+00  3.0517578e-05\n",
      " -3.0517578e-05 -9.1552734e-05 -6.1035156e-05 -6.1035156e-05\n",
      "  0.0000000e+00  3.0517578e-05  0.0000000e+00 -6.1035156e-05\n",
      " -1.5258789e-04 -3.0517578e-04 -3.6621094e-04 -4.5776367e-04\n",
      " -5.7983398e-04 -6.1035156e-04 -6.4086914e-04 -6.4086914e-04\n",
      " -5.1879883e-04 -3.6621094e-04 -3.3569336e-04 -3.3569336e-04\n",
      " -3.3569336e-04 -1.5258789e-04 -3.0517578e-05 -3.0517578e-05\n",
      "  3.0517578e-05  1.8310547e-04  2.7465820e-04  2.4414062e-04\n",
      "  1.8310547e-04  1.5258789e-04  1.5258789e-04  3.0517578e-05\n",
      " -1.2207031e-04 -2.4414062e-04 -2.1362305e-04 -1.8310547e-04\n",
      " -2.1362305e-04 -2.7465820e-04 -3.0517578e-04 -3.0517578e-04\n",
      " -3.3569336e-04 -3.0517578e-04 -2.4414062e-04 -1.8310547e-04\n",
      " -2.4414062e-04 -2.7465820e-04 -1.8310547e-04 -1.5258789e-04\n",
      " -1.8310547e-04 -2.7465820e-04 -3.9672852e-04 -4.5776367e-04\n",
      " -4.2724609e-04 -3.9672852e-04 -3.3569336e-04 -2.7465820e-04\n",
      " -1.8310547e-04 -1.8310547e-04 -2.1362305e-04 -2.7465820e-04\n",
      " -2.1362305e-04 -2.7465820e-04 -4.2724609e-04 -4.8828125e-04\n",
      " -4.5776367e-04 -3.9672852e-04 -1.8310547e-04 -1.5258789e-04\n",
      " -1.5258789e-04 -2.1362305e-04 -1.8310547e-04 -1.2207031e-04\n",
      " -1.8310547e-04 -3.6621094e-04 -3.9672852e-04 -3.9672852e-04\n",
      " -5.7983398e-04 -6.7138672e-04 -6.4086914e-04 -6.7138672e-04\n",
      " -6.7138672e-04 -7.6293945e-04 -8.2397461e-04 -7.9345703e-04\n",
      " -7.0190430e-04 -5.4931641e-04 -4.5776367e-04 -5.7983398e-04\n",
      " -4.8828125e-04 -2.7465820e-04 -2.1362305e-04 -2.1362305e-04\n",
      " -1.2207031e-04  0.0000000e+00  6.1035156e-05  0.0000000e+00\n",
      " -6.1035156e-05  0.0000000e+00 -3.0517578e-05 -9.1552734e-05\n",
      " -1.2207031e-04 -2.1362305e-04 -2.4414062e-04 -1.2207031e-04\n",
      "  0.0000000e+00 -3.0517578e-05  0.0000000e+00 -9.1552734e-05\n",
      " -1.5258789e-04 -1.8310547e-04 -2.1362305e-04 -1.5258789e-04\n",
      " -9.1552734e-05 -1.5258789e-04 -6.1035156e-05  6.1035156e-05]\n",
      "scipy.io.wavfile運行時間: 0.028084 秒\n",
      "[ -2  -3  -3  -2   0  -1  -1  -1  -2  -3  -4  -4  -3  -2  -2  -3  -3  -3\n",
      "  -3  -2  -2  -1   0  -1  -1   0   1   2   3   3   4   4   3   2   2   2\n",
      "   2   2   2   2   1   1   0  -1  -1  -2  -2  -3  -4  -4  -5  -5  -4  -3\n",
      "  -4  -3  -4  -3  -3  -3  -2   0   1   2   2   2   2   3   2   2   3   3\n",
      "   1   0   0   0   1   1   1   1   1  -1  -2  -3  -2   0  -2   0   0   0\n",
      "  -1  -1  -1   0   0   0   0   0  -1  -1  -1   0  -1   0   0  -1  -1  -1\n",
      "  -1   0   0   0   0  -1  -1  -1  -1  -1   0   0   0   0  -1  -1  -1  -1\n",
      "   0   0   0   0  -1  -1  -1  -1   0   0   0   0  -1  -1  -1   0  -1   0\n",
      "   0   0  -1  -1  -1  -1   0   0   0  -1  -1  -1  -1  -1   0   0   0   0\n",
      "  -1  -1  -1  -1   0   0   0   0   0  -1  -1  -1   0  -1   0   0  -1  -1\n",
      "  -1  -1   0   0   0   0  -1  -1  -1  -1   0   0   0   0  -1  -1  -1  -1\n",
      "  -1   0   0   0  -1   0  -1  -1   0  -1   0  -1   0  -1  -2   0  -1   0\n",
      "   1   0   0  -1  -1  -1  -1  -1   0   0  -1   0  -1  -1  -1   0   0  -1\n",
      "   0  -1  -1  -2  -1   0   0   0   0  -1  -1  -1   0   0  -1   0  -1  -1\n",
      "  -1  -1   0  -1   0   0   0  -1   0  -2  -1  -1   0   1  -1   0  -1  -1\n",
      "  -1   0   0   0  -1  -1  -1  -2   0  -1   0   0   0   0  -1  -1  -1  -1\n",
      "   0   0   0   0  -2   0  -1  -1   0   0  -1   0  -1  -1   0  -1   0   4\n",
      "   0   1   0  -1   0  -1  -1   0  -1  -1   0  -2  -3  -3  -3  -2   1   0\n",
      "   2   0   0   1   1   0   1   0  -1   0   1   0   0  -2  -2  -3  -4  -2\n",
      "  -1  -2  -1   0   0   0   1  -1   0  -1   0   3   2   1   1  -2  -2  -1\n",
      "  -2  -1  -1  -2  -1  -2  -1  -1   0  -3   0   0   0   2   1   1   1   0\n",
      "   1   1  -1  -1  -1  -3  -1  -1  -1  -2  -2  -3  -2  -1   0   2   0   1\n",
      "   1   1   0   1   0   0   0   1   0  -1  -2  -2  -3  -3  -1   0  -1  -1\n",
      "  -1  -1   0   1   1   1   0   1   1   0   0   0  -1  -1  -1   0  -2  -2\n",
      "  -3  -2  -3  -1   0   0  -2   0   0   1   1   2   2  -1   0   0   0   0\n",
      "   0  -1  -2  -3  -1  -2  -3  -2  -1  -1   0   1  -1   0  -2   1   2   1\n",
      "   2   3  -1  -1  -1  -2  -1  -1  -2  -1  -2  -2   1  -3  -2  -1  -2   0\n",
      "   1   1   1   1   0   2   1  -1   0  -2  -3   0   0  -1   0  -3  -3  -3\n",
      "  -4  -1   1  -1   2   2   0   1   0  -1   0  -1   1   2   1   0   0  -4\n",
      "  -4  -1  -3  -2   0  -2   0   0   0   2  -2  -2   1   0   1   3   2   1\n",
      "   0  -1  -1  -2  -3  -1  -1  -3   1   0  -2  -1  -2  -3   0   0   2   3\n",
      "   0   2   2  -1   0  -1  -2  -2  -1   0   0  -1  -2  -2  -4  -3   0  -1\n",
      "   0   1   1   1   1   1   1  -1  -1   1   1   0   2  -1  -2  -3  -3  -2\n",
      "  -2  -2   0  -1   0   0   2  -1  -1   0   0   1   3   2   1   0  -1  -1\n",
      "  -2  -2  -1  -2  -2  -1   0  -1  -1  -2  -1  -1   0   2   2   1   1   1\n",
      "   0   0   0  -1  -2  -1  -1  -1  -1  -2  -2  -3  -2  -1   0  -1   0   1\n",
      "   0   1   2   0   0  -1   0   1   0   0   0  -3  -3  -1  -2  -2  -1  -2\n",
      "  -1  -1   0   2   0  -1   1   0   0   2   1   0   0  -1  -1  -1  -2  -1\n",
      "  -2  -4  -1  -1  -2   0  -1  -2   1   0   2   2   0   0   2  -1   1   1\n",
      "  -1  -1  -1  -2  -1  -2  -3  -1  -3  -2   1   0   0   1  -1   0   1   1\n",
      "   2   1  -1   1   0  -2   0  -1  -3  -2  -2  -2   0  -2  -1  -2  -2   0\n",
      "   2   0   1   2   0   2   1  12  10   4   0   3   0  -2  -3  -5  -6  -5\n",
      "  -6  -4  -4  -5  -4  -4  -5  -2  -1  -4  -6  -5  -4  -4  -7  -9  -8 -13\n",
      " -15 -11  -8  -6  -6  -5   1   2   0   1  -1  -3  -2  -2   0   1   0  -2\n",
      "  -5 -10 -12 -15 -19 -20 -21 -21 -17 -12 -11 -11 -11  -5  -1  -1   1   6\n",
      "   9   8   6   5   5   1  -4  -8  -7  -6  -7  -9 -10 -10 -11 -10  -8  -6\n",
      "  -8  -9  -6  -5  -6  -9 -13 -15 -14 -13 -11  -9  -6  -6  -7  -9  -7  -9\n",
      " -14 -16 -15 -13  -6  -5  -5  -7  -6  -4  -6 -12 -13 -13 -19 -22 -21 -22\n",
      " -22 -25 -27 -26 -23 -18 -15 -19 -16  -9  -7  -7  -4   0   2   0  -2   0\n",
      "  -1  -3  -4  -7  -8  -4   0  -1   0  -3  -5  -6  -7  -5  -3  -5  -2   2]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import scipy.io.wavfile\n",
    "import timeit\n",
    "\n",
    "# 設定音檔路徑\n",
    "audio_file = '/mnt/Internal/FedASR/Data/ADReSS-IS2020-data/clips/S001_INV_0_0_2360.wav'\n",
    "\n",
    "# 使用librosa.load測試時間\n",
    "def librosa_load_time():\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    return y[100:1000]\n",
    "    \n",
    "# 使用scipy.io.wavfile測試時間\n",
    "def scipy_read_time():\n",
    "    sr, y = scipy.io.wavfile.read(audio_file)\n",
    "    return y[100:1000]\n",
    "    \n",
    "# 測量librosa.load運行時間\n",
    "librosa_load_duration = timeit.timeit(librosa_load_time, number=100)\n",
    "print(f'librosa.load運行時間: {librosa_load_duration:.6f} 秒')\n",
    "\n",
    "y_lib=librosa_load_time()\n",
    "\n",
    "print(y_lib)\n",
    "\n",
    "# 測量scipy.io.wavfile運行時間\n",
    "scipy_read_duration = timeit.timeit(scipy_read_time, number=100)\n",
    "print(f'scipy.io.wavfile運行時間: {scipy_read_duration:.6f} 秒')\n",
    "\n",
    "y_scipy=scipy_read_time()\n",
    "\n",
    "print(y_scipy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def csv2dataset():\n",
    "audio_path = '{}/clips/'.format(args.root_dir),\n",
    "csv_path = '{}/mid_csv/test.csv'.format(args.root_dir)\n",
    "stored = \"./dataset/\" + csv_path.split(\"/\")[-1].split(\".\")[0]\n",
    "if (os.path.exists(stored)):\n",
    "    #print(\"loaded\")\n",
    "    return load_from_disk(stored)\n",
    "    \n",
    "data = pd.read_csv(csv_path)                                                # read desired csv\n",
    "dataset = Dataset.from_pandas(data)                                     # turn into class dataset\n",
    "\n",
    "# initialize a dictionary\n",
    "my_dict = {}\n",
    "my_dict[\"path\"] = []                                                   # path to audio\n",
    "my_dict[\"array\"] = []                                                  # waveform in array\n",
    "my_dict[\"text\"] = []                                                   # ground truth transcript\n",
    "\n",
    "i = 1\n",
    "for file_path in dataset['path']:                                           # for all files\n",
    "    if dataset['sentence'][i-1] != None:                               # only the non-empty transcript\n",
    "        sig, s = librosa.load('{0}/{1}'.format(audio_path,file_path), sr=args.sampl_rate, dtype='float32')  # read audio w/ 16k sr\n",
    "        my_dict[\"path\"].append(file_path)                                   # add path\n",
    "        my_dict[\"array\"].append(sig)                                   # add audio wave\n",
    "        my_dict[\"text\"].append(dataset['sentence'][i-1].upper())       # transcript to uppercase\n",
    "    print(i, end=\"\\r\")                                                 # print progress\n",
    "    i += 1\n",
    "print(\"There're \", len(my_dict[\"path\"]), \" non-empty files.\")\n",
    "\n",
    "result_dataset = Dataset.from_dict(my_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if model_type == \"wav2vec\":\n",
    "    name = \"facebook/wav2vec2-base-960h\" # + model_dir.split(\"/\")[-3]\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(name)\n",
    "    print(\"Current model: \", name)\n",
    "    processor = Wav2Vec2Processor.from_pretrained(name)\n",
    "elif model_type == \"data2vec\":\n",
    "    name = \"facebook/data2vec-audio-large-960h\" # + model_in_dir.split(\"/\")[-3]\n",
    "    print(\"Current model: \", name)\n",
    "    mask_time_prob = 0                                                                     # change config\n",
    "    config = Data2VecAudioConfig.from_pretrained(name, mask_time_prob=mask_time_prob)\n",
    "    model = Data2VecAudioForCTC.from_pretrained(name, config=config)\n",
    "    processor = Wav2Vec2Processor.from_pretrained(name)\n",
    "elif model_type == \"hubert\":\n",
    "    name = \"facebook/hubert-xlarge-ls960-ft\" # + model_in_dir.split(\"/\")[-3]\n",
    "    print(\"Current model: \", name)\n",
    "    mask_time_prob = 0                                                                     # change config\n",
    "    config = HubertConfig.from_pretrained(name, mask_time_prob=mask_time_prob)\n",
    "    model = HubertForCTC.from_pretrained(name, config=config)\n",
    "    processor = Wav2Vec2Processor.from_pretrained(name)\n",
    "elif model_type == \"sewd\":\n",
    "    name = \"asapp/sew-d-mid-400k-ft-ls100h\" #+ model_in_dir.split(\"/\")[-3]\n",
    "    print(\"Current model: \", name)\n",
    "    mask_time_prob = 0                                                                     # change config\n",
    "    config = SEWDConfig.from_pretrained(name, mask_time_prob=mask_time_prob)\n",
    "    model = SEWDForCTC.from_pretrained(name, config=config)\n",
    "    processor = Wav2Vec2Processor.from_pretrained(name)\n",
    "elif model_type == \"unispeech\":\n",
    "    name = \"microsoft/unispeech-sat-base-100h-libri-ft\" # + model_in_dir.split(\"/\")[-3]\n",
    "    print(\"Current model: \", name)\n",
    "    mask_time_prob = 0                                                                     # change config\n",
    "    config = UniSpeechSatConfig.from_pretrained(name, mask_time_prob=mask_time_prob)\n",
    "    model = UniSpeechSatForCTC.from_pretrained(name, config=config)\n",
    "    processor = Wav2Vec2Processor.from_pretrained(name)\n",
    "else:\n",
    "    print(\"WRONG TYPE!!!!!!!!!!!!!!!!\")\n",
    "\n",
    "\n",
    "# use processor to get labels\n",
    "train_data = train_data.map(prepare_dataset, num_proc=4)\n",
    "dev_data = dev_data.map(prepare_dataset, num_proc=4)\n",
    "test_data = test_data.map(prepare_dataset, num_proc=4)\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "\n",
    "model.freeze_feature_encoder()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./saves/\" + name.split(\"/\")[-1] + \"_finetuned\",\n",
    "    group_by_length=True,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=30,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True, \n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    logging_steps=500,\n",
    "    learning_rate=lr,\n",
    "    weight_decay=0.005,\n",
    "    warmup_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    optim=optim,\n",
    "    max_grad_norm=max_grad_norm,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=dev_data,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model(\"./saves/\" + name.split(\"/\")[-1] + \"_finetuned/final\")\n",
    "\n",
    "# load in trained model\n",
    "if model_type == \"wav2vec\":\n",
    "    new_model = Wav2Vec2ForCTC.from_pretrained(\"./saves/\" + name.split(\"/\")[-1] + \"_finetuned/final\")\n",
    "    new_processor = Wav2Vec2Processor.from_pretrained(name)\n",
    "elif model_type == \"data2vec\":\n",
    "    new_model = Data2VecAudioForCTC.from_pretrained(\"./saves/\" + name.split(\"/\")[-1] + \"_finetuned/final\")\n",
    "    new_processor = Wav2Vec2Processor.from_pretrained(name)\n",
    "elif model_type == \"hubert\":\n",
    "    new_model = HubertForCTC.from_pretrained(\"./saves/\" + name.split(\"/\")[-1] + \"_finetuned/final\")\n",
    "    new_processor = Wav2Vec2Processor.from_pretrained(name)\n",
    "elif model_type == \"sewd\":\n",
    "    new_model = SEWDForCTC.from_pretrained(\"./saves/\" + name.split(\"/\")[-1] + \"_finetuned/final\")\n",
    "    new_processor = Wav2Vec2Processor.from_pretrained(name)\n",
    "elif model_type == \"unispeech\":\n",
    "    new_model = UniSpeechSatForCTC.from_pretrained(\"./saves/\" + name.split(\"/\")[-1] + \"_finetuned/final\")\n",
    "    new_processor = Wav2Vec2Processor.from_pretrained(name)\n",
    "else:\n",
    "    print(\"WRONG TYPE!!!!!!!!!!!!!!!!\")\n",
    "\n",
    "result = test_data.map(map_to_result)\n",
    "print(\"WER of \", name, \" : \", wer(result[\"text\"], result[\"pred_str\"]))\n",
    "print(\"DONE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flower-speechbrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
